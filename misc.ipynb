{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/ckwan1/.conda/envs/d3m/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from datapile import FastPMPile, HuggingfaceLoader, CSVHDF5DataModule\n",
    "from model import Lpt2NbodyNetLightning\n",
    "import yaml\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/user/ckwan1/ml_project/field2field/configs/styledunet.yaml\"\n",
    "config = load_config(path)\n",
    "config['model']['num_layers'] = 4\n",
    "config['model']['base_filters']  = 4\n",
    "model = Lpt2NbodyNetLightning(**config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['data']['batch_size'] = 1\n",
    "config['data']['num_workers'] = 1\n",
    "data = HuggingfaceLoader(**config['data'])\n",
    "data.setup(\"validation\")\n",
    "val_iter = iter(data.val_dataloader())\n",
    "batch = next(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/user/ckwan1/ml_project/field2field/configs/32/naf_finetune_s8.yaml\"\n",
    "config = load_config(path)\n",
    "config['data']['batch_size'] = 1\n",
    "config['data']['num_workers'] = 1\n",
    "data = CSVHDF5DataModule(**config['data'])\n",
    "data.setup(\"validation\")\n",
    "val_iter = iter(data.val_dataloader())\n",
    "batch = next(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.6884, 0.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3739579/675966113.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  post_ckpt = torch.load(\"/home/user/ckwan1/ml_project/field2field/new_checkpoints/naf_finetune_dummy/best-checkpoint-epoch=99.ckpt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path1=\"/home/user/ckwan1/ml_project/field2field/configs/32/naf_finetune_s8.yaml\"\n",
    "config1 = load_config(path1)\n",
    "model = Lpt2NbodyNetLightning(**config1['model'])\n",
    "post_ckpt = torch.load(\"/home/user/ckwan1/ml_project/field2field/new_checkpoints/naf_finetune_dummy/best-checkpoint-epoch=99.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "model.load_state_dict(post_ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3739579/2805961183.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pt_ckpt = torch.load(\"/home/user/ckwan1/ml_project/field2field/new_checkpoints/naf_base_sca_denoise_32/best-checkpoint-epoch=2303_c.ckpt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['model.encoders.0.0.mod_conv1.style_weight', 'model.encoders.0.0.mod_conv1.style_bias', 'model.encoders.0.0.mod_conv1.weight', 'model.encoders.0.0.mod_conv1.bias', 'model.encoders.0.0.mod_conv2.style_weight', 'model.encoders.0.0.mod_conv2.style_bias', 'model.encoders.0.0.mod_conv2.weight', 'model.encoders.0.0.mod_conv2.bias', 'model.encoders.0.0.mod_conv3.style_weight', 'model.encoders.0.0.mod_conv3.style_bias', 'model.encoders.0.0.mod_conv3.weight', 'model.encoders.0.0.mod_conv3.bias', 'model.encoders.0.0.sca_conv.style_weight', 'model.encoders.0.0.sca_conv.style_bias', 'model.encoders.0.0.sca_conv.weight', 'model.encoders.0.0.sca_conv.bias', 'model.encoders.0.0.mod_conv4.style_weight', 'model.encoders.0.0.mod_conv4.style_bias', 'model.encoders.0.0.mod_conv4.weight', 'model.encoders.0.0.mod_conv4.bias', 'model.encoders.0.0.mod_conv5.style_weight', 'model.encoders.0.0.mod_conv5.style_bias', 'model.encoders.0.0.mod_conv5.weight', 'model.encoders.0.0.mod_conv5.bias', 'model.encoders.0.1.mod_conv1.style_weight', 'model.encoders.0.1.mod_conv1.style_bias', 'model.encoders.0.1.mod_conv1.weight', 'model.encoders.0.1.mod_conv1.bias', 'model.encoders.0.1.mod_conv2.style_weight', 'model.encoders.0.1.mod_conv2.style_bias', 'model.encoders.0.1.mod_conv2.weight', 'model.encoders.0.1.mod_conv2.bias', 'model.encoders.0.1.mod_conv3.style_weight', 'model.encoders.0.1.mod_conv3.style_bias', 'model.encoders.0.1.mod_conv3.weight', 'model.encoders.0.1.mod_conv3.bias', 'model.encoders.0.1.sca_conv.style_weight', 'model.encoders.0.1.sca_conv.style_bias', 'model.encoders.0.1.sca_conv.weight', 'model.encoders.0.1.sca_conv.bias', 'model.encoders.0.1.mod_conv4.style_weight', 'model.encoders.0.1.mod_conv4.style_bias', 'model.encoders.0.1.mod_conv4.weight', 'model.encoders.0.1.mod_conv4.bias', 'model.encoders.0.1.mod_conv5.style_weight', 'model.encoders.0.1.mod_conv5.style_bias', 'model.encoders.0.1.mod_conv5.weight', 'model.encoders.0.1.mod_conv5.bias', 'model.encoders.1.0.mod_conv1.style_weight', 'model.encoders.1.0.mod_conv1.style_bias', 'model.encoders.1.0.mod_conv1.weight', 'model.encoders.1.0.mod_conv1.bias', 'model.encoders.1.0.mod_conv2.style_weight', 'model.encoders.1.0.mod_conv2.style_bias', 'model.encoders.1.0.mod_conv2.weight', 'model.encoders.1.0.mod_conv2.bias', 'model.encoders.1.0.mod_conv3.style_weight', 'model.encoders.1.0.mod_conv3.style_bias', 'model.encoders.1.0.mod_conv3.weight', 'model.encoders.1.0.mod_conv3.bias', 'model.encoders.1.0.sca_conv.style_weight', 'model.encoders.1.0.sca_conv.style_bias', 'model.encoders.1.0.sca_conv.weight', 'model.encoders.1.0.sca_conv.bias', 'model.encoders.1.0.mod_conv4.style_weight', 'model.encoders.1.0.mod_conv4.style_bias', 'model.encoders.1.0.mod_conv4.weight', 'model.encoders.1.0.mod_conv4.bias', 'model.encoders.1.0.mod_conv5.style_weight', 'model.encoders.1.0.mod_conv5.style_bias', 'model.encoders.1.0.mod_conv5.weight', 'model.encoders.1.0.mod_conv5.bias', 'model.encoders.1.1.mod_conv1.style_weight', 'model.encoders.1.1.mod_conv1.style_bias', 'model.encoders.1.1.mod_conv1.weight', 'model.encoders.1.1.mod_conv1.bias', 'model.encoders.1.1.mod_conv2.style_weight', 'model.encoders.1.1.mod_conv2.style_bias', 'model.encoders.1.1.mod_conv2.weight', 'model.encoders.1.1.mod_conv2.bias', 'model.encoders.1.1.mod_conv3.style_weight', 'model.encoders.1.1.mod_conv3.style_bias', 'model.encoders.1.1.mod_conv3.weight', 'model.encoders.1.1.mod_conv3.bias', 'model.encoders.1.1.sca_conv.style_weight', 'model.encoders.1.1.sca_conv.style_bias', 'model.encoders.1.1.sca_conv.weight', 'model.encoders.1.1.sca_conv.bias', 'model.encoders.1.1.mod_conv4.style_weight', 'model.encoders.1.1.mod_conv4.style_bias', 'model.encoders.1.1.mod_conv4.weight', 'model.encoders.1.1.mod_conv4.bias', 'model.encoders.1.1.mod_conv5.style_weight', 'model.encoders.1.1.mod_conv5.style_bias', 'model.encoders.1.1.mod_conv5.weight', 'model.encoders.1.1.mod_conv5.bias', 'model.encoders.2.0.mod_conv1.style_weight', 'model.encoders.2.0.mod_conv1.style_bias', 'model.encoders.2.0.mod_conv1.weight', 'model.encoders.2.0.mod_conv1.bias', 'model.encoders.2.0.mod_conv2.style_weight', 'model.encoders.2.0.mod_conv2.style_bias', 'model.encoders.2.0.mod_conv2.weight', 'model.encoders.2.0.mod_conv2.bias', 'model.encoders.2.0.mod_conv3.style_weight', 'model.encoders.2.0.mod_conv3.style_bias', 'model.encoders.2.0.mod_conv3.weight', 'model.encoders.2.0.mod_conv3.bias', 'model.encoders.2.0.sca_conv.style_weight', 'model.encoders.2.0.sca_conv.style_bias', 'model.encoders.2.0.sca_conv.weight', 'model.encoders.2.0.sca_conv.bias', 'model.encoders.2.0.mod_conv4.style_weight', 'model.encoders.2.0.mod_conv4.style_bias', 'model.encoders.2.0.mod_conv4.weight', 'model.encoders.2.0.mod_conv4.bias', 'model.encoders.2.0.mod_conv5.style_weight', 'model.encoders.2.0.mod_conv5.style_bias', 'model.encoders.2.0.mod_conv5.weight', 'model.encoders.2.0.mod_conv5.bias', 'model.encoders.2.1.mod_conv1.style_weight', 'model.encoders.2.1.mod_conv1.style_bias', 'model.encoders.2.1.mod_conv1.weight', 'model.encoders.2.1.mod_conv1.bias', 'model.encoders.2.1.mod_conv2.style_weight', 'model.encoders.2.1.mod_conv2.style_bias', 'model.encoders.2.1.mod_conv2.weight', 'model.encoders.2.1.mod_conv2.bias', 'model.encoders.2.1.mod_conv3.style_weight', 'model.encoders.2.1.mod_conv3.style_bias', 'model.encoders.2.1.mod_conv3.weight', 'model.encoders.2.1.mod_conv3.bias', 'model.encoders.2.1.sca_conv.style_weight', 'model.encoders.2.1.sca_conv.style_bias', 'model.encoders.2.1.sca_conv.weight', 'model.encoders.2.1.sca_conv.bias', 'model.encoders.2.1.mod_conv4.style_weight', 'model.encoders.2.1.mod_conv4.style_bias', 'model.encoders.2.1.mod_conv4.weight', 'model.encoders.2.1.mod_conv4.bias', 'model.encoders.2.1.mod_conv5.style_weight', 'model.encoders.2.1.mod_conv5.style_bias', 'model.encoders.2.1.mod_conv5.weight', 'model.encoders.2.1.mod_conv5.bias', 'model.encoders.2.2.mod_conv1.style_weight', 'model.encoders.2.2.mod_conv1.style_bias', 'model.encoders.2.2.mod_conv1.weight', 'model.encoders.2.2.mod_conv1.bias', 'model.encoders.2.2.mod_conv2.style_weight', 'model.encoders.2.2.mod_conv2.style_bias', 'model.encoders.2.2.mod_conv2.weight', 'model.encoders.2.2.mod_conv2.bias', 'model.encoders.2.2.mod_conv3.style_weight', 'model.encoders.2.2.mod_conv3.style_bias', 'model.encoders.2.2.mod_conv3.weight', 'model.encoders.2.2.mod_conv3.bias', 'model.encoders.2.2.sca_conv.style_weight', 'model.encoders.2.2.sca_conv.style_bias', 'model.encoders.2.2.sca_conv.weight', 'model.encoders.2.2.sca_conv.bias', 'model.encoders.2.2.mod_conv4.style_weight', 'model.encoders.2.2.mod_conv4.style_bias', 'model.encoders.2.2.mod_conv4.weight', 'model.encoders.2.2.mod_conv4.bias', 'model.encoders.2.2.mod_conv5.style_weight', 'model.encoders.2.2.mod_conv5.style_bias', 'model.encoders.2.2.mod_conv5.weight', 'model.encoders.2.2.mod_conv5.bias', 'model.encoders.2.3.mod_conv1.style_weight', 'model.encoders.2.3.mod_conv1.style_bias', 'model.encoders.2.3.mod_conv1.weight', 'model.encoders.2.3.mod_conv1.bias', 'model.encoders.2.3.mod_conv2.style_weight', 'model.encoders.2.3.mod_conv2.style_bias', 'model.encoders.2.3.mod_conv2.weight', 'model.encoders.2.3.mod_conv2.bias', 'model.encoders.2.3.mod_conv3.style_weight', 'model.encoders.2.3.mod_conv3.style_bias', 'model.encoders.2.3.mod_conv3.weight', 'model.encoders.2.3.mod_conv3.bias', 'model.encoders.2.3.sca_conv.style_weight', 'model.encoders.2.3.sca_conv.style_bias', 'model.encoders.2.3.sca_conv.weight', 'model.encoders.2.3.sca_conv.bias', 'model.encoders.2.3.mod_conv4.style_weight', 'model.encoders.2.3.mod_conv4.style_bias', 'model.encoders.2.3.mod_conv4.weight', 'model.encoders.2.3.mod_conv4.bias', 'model.encoders.2.3.mod_conv5.style_weight', 'model.encoders.2.3.mod_conv5.style_bias', 'model.encoders.2.3.mod_conv5.weight', 'model.encoders.2.3.mod_conv5.bias', 'model.encoders.3.0.mod_conv1.style_weight', 'model.encoders.3.0.mod_conv1.style_bias', 'model.encoders.3.0.mod_conv1.weight', 'model.encoders.3.0.mod_conv1.bias', 'model.encoders.3.0.mod_conv2.style_weight', 'model.encoders.3.0.mod_conv2.style_bias', 'model.encoders.3.0.mod_conv2.weight', 'model.encoders.3.0.mod_conv2.bias', 'model.encoders.3.0.mod_conv3.style_weight', 'model.encoders.3.0.mod_conv3.style_bias', 'model.encoders.3.0.mod_conv3.weight', 'model.encoders.3.0.mod_conv3.bias', 'model.encoders.3.0.sca_conv.style_weight', 'model.encoders.3.0.sca_conv.style_bias', 'model.encoders.3.0.sca_conv.weight', 'model.encoders.3.0.sca_conv.bias', 'model.encoders.3.0.mod_conv4.style_weight', 'model.encoders.3.0.mod_conv4.style_bias', 'model.encoders.3.0.mod_conv4.weight', 'model.encoders.3.0.mod_conv4.bias', 'model.encoders.3.0.mod_conv5.style_weight', 'model.encoders.3.0.mod_conv5.style_bias', 'model.encoders.3.0.mod_conv5.weight', 'model.encoders.3.0.mod_conv5.bias', 'model.encoders.3.1.mod_conv1.style_weight', 'model.encoders.3.1.mod_conv1.style_bias', 'model.encoders.3.1.mod_conv1.weight', 'model.encoders.3.1.mod_conv1.bias', 'model.encoders.3.1.mod_conv2.style_weight', 'model.encoders.3.1.mod_conv2.style_bias', 'model.encoders.3.1.mod_conv2.weight', 'model.encoders.3.1.mod_conv2.bias', 'model.encoders.3.1.mod_conv3.style_weight', 'model.encoders.3.1.mod_conv3.style_bias', 'model.encoders.3.1.mod_conv3.weight', 'model.encoders.3.1.mod_conv3.bias', 'model.encoders.3.1.sca_conv.style_weight', 'model.encoders.3.1.sca_conv.style_bias', 'model.encoders.3.1.sca_conv.weight', 'model.encoders.3.1.sca_conv.bias', 'model.encoders.3.1.mod_conv4.style_weight', 'model.encoders.3.1.mod_conv4.style_bias', 'model.encoders.3.1.mod_conv4.weight', 'model.encoders.3.1.mod_conv4.bias', 'model.encoders.3.1.mod_conv5.style_weight', 'model.encoders.3.1.mod_conv5.style_bias', 'model.encoders.3.1.mod_conv5.weight', 'model.encoders.3.1.mod_conv5.bias', 'model.encoders.3.2.mod_conv1.style_weight', 'model.encoders.3.2.mod_conv1.style_bias', 'model.encoders.3.2.mod_conv1.weight', 'model.encoders.3.2.mod_conv1.bias', 'model.encoders.3.2.mod_conv2.style_weight', 'model.encoders.3.2.mod_conv2.style_bias', 'model.encoders.3.2.mod_conv2.weight', 'model.encoders.3.2.mod_conv2.bias', 'model.encoders.3.2.mod_conv3.style_weight', 'model.encoders.3.2.mod_conv3.style_bias', 'model.encoders.3.2.mod_conv3.weight', 'model.encoders.3.2.mod_conv3.bias', 'model.encoders.3.2.sca_conv.style_weight', 'model.encoders.3.2.sca_conv.style_bias', 'model.encoders.3.2.sca_conv.weight', 'model.encoders.3.2.sca_conv.bias', 'model.encoders.3.2.mod_conv4.style_weight', 'model.encoders.3.2.mod_conv4.style_bias', 'model.encoders.3.2.mod_conv4.weight', 'model.encoders.3.2.mod_conv4.bias', 'model.encoders.3.2.mod_conv5.style_weight', 'model.encoders.3.2.mod_conv5.style_bias', 'model.encoders.3.2.mod_conv5.weight', 'model.encoders.3.2.mod_conv5.bias', 'model.encoders.3.3.mod_conv1.style_weight', 'model.encoders.3.3.mod_conv1.style_bias', 'model.encoders.3.3.mod_conv1.weight', 'model.encoders.3.3.mod_conv1.bias', 'model.encoders.3.3.mod_conv2.style_weight', 'model.encoders.3.3.mod_conv2.style_bias', 'model.encoders.3.3.mod_conv2.weight', 'model.encoders.3.3.mod_conv2.bias', 'model.encoders.3.3.mod_conv3.style_weight', 'model.encoders.3.3.mod_conv3.style_bias', 'model.encoders.3.3.mod_conv3.weight', 'model.encoders.3.3.mod_conv3.bias', 'model.encoders.3.3.sca_conv.style_weight', 'model.encoders.3.3.sca_conv.style_bias', 'model.encoders.3.3.sca_conv.weight', 'model.encoders.3.3.sca_conv.bias', 'model.encoders.3.3.mod_conv4.style_weight', 'model.encoders.3.3.mod_conv4.style_bias', 'model.encoders.3.3.mod_conv4.weight', 'model.encoders.3.3.mod_conv4.bias', 'model.encoders.3.3.mod_conv5.style_weight', 'model.encoders.3.3.mod_conv5.style_bias', 'model.encoders.3.3.mod_conv5.weight', 'model.encoders.3.3.mod_conv5.bias', 'model.encoders.3.4.mod_conv1.style_weight', 'model.encoders.3.4.mod_conv1.style_bias', 'model.encoders.3.4.mod_conv1.weight', 'model.encoders.3.4.mod_conv1.bias', 'model.encoders.3.4.mod_conv2.style_weight', 'model.encoders.3.4.mod_conv2.style_bias', 'model.encoders.3.4.mod_conv2.weight', 'model.encoders.3.4.mod_conv2.bias', 'model.encoders.3.4.mod_conv3.style_weight', 'model.encoders.3.4.mod_conv3.style_bias', 'model.encoders.3.4.mod_conv3.weight', 'model.encoders.3.4.mod_conv3.bias', 'model.encoders.3.4.sca_conv.style_weight', 'model.encoders.3.4.sca_conv.style_bias', 'model.encoders.3.4.sca_conv.weight', 'model.encoders.3.4.sca_conv.bias', 'model.encoders.3.4.mod_conv4.style_weight', 'model.encoders.3.4.mod_conv4.style_bias', 'model.encoders.3.4.mod_conv4.weight', 'model.encoders.3.4.mod_conv4.bias', 'model.encoders.3.4.mod_conv5.style_weight', 'model.encoders.3.4.mod_conv5.style_bias', 'model.encoders.3.4.mod_conv5.weight', 'model.encoders.3.4.mod_conv5.bias', 'model.encoders.3.5.mod_conv1.style_weight', 'model.encoders.3.5.mod_conv1.style_bias', 'model.encoders.3.5.mod_conv1.weight', 'model.encoders.3.5.mod_conv1.bias', 'model.encoders.3.5.mod_conv2.style_weight', 'model.encoders.3.5.mod_conv2.style_bias', 'model.encoders.3.5.mod_conv2.weight', 'model.encoders.3.5.mod_conv2.bias', 'model.encoders.3.5.mod_conv3.style_weight', 'model.encoders.3.5.mod_conv3.style_bias', 'model.encoders.3.5.mod_conv3.weight', 'model.encoders.3.5.mod_conv3.bias', 'model.encoders.3.5.sca_conv.style_weight', 'model.encoders.3.5.sca_conv.style_bias', 'model.encoders.3.5.sca_conv.weight', 'model.encoders.3.5.sca_conv.bias', 'model.encoders.3.5.mod_conv4.style_weight', 'model.encoders.3.5.mod_conv4.style_bias', 'model.encoders.3.5.mod_conv4.weight', 'model.encoders.3.5.mod_conv4.bias', 'model.encoders.3.5.mod_conv5.style_weight', 'model.encoders.3.5.mod_conv5.style_bias', 'model.encoders.3.5.mod_conv5.weight', 'model.encoders.3.5.mod_conv5.bias', 'model.encoders.3.6.mod_conv1.style_weight', 'model.encoders.3.6.mod_conv1.style_bias', 'model.encoders.3.6.mod_conv1.weight', 'model.encoders.3.6.mod_conv1.bias', 'model.encoders.3.6.mod_conv2.style_weight', 'model.encoders.3.6.mod_conv2.style_bias', 'model.encoders.3.6.mod_conv2.weight', 'model.encoders.3.6.mod_conv2.bias', 'model.encoders.3.6.mod_conv3.style_weight', 'model.encoders.3.6.mod_conv3.style_bias', 'model.encoders.3.6.mod_conv3.weight', 'model.encoders.3.6.mod_conv3.bias', 'model.encoders.3.6.sca_conv.style_weight', 'model.encoders.3.6.sca_conv.style_bias', 'model.encoders.3.6.sca_conv.weight', 'model.encoders.3.6.sca_conv.bias', 'model.encoders.3.6.mod_conv4.style_weight', 'model.encoders.3.6.mod_conv4.style_bias', 'model.encoders.3.6.mod_conv4.weight', 'model.encoders.3.6.mod_conv4.bias', 'model.encoders.3.6.mod_conv5.style_weight', 'model.encoders.3.6.mod_conv5.style_bias', 'model.encoders.3.6.mod_conv5.weight', 'model.encoders.3.6.mod_conv5.bias', 'model.encoders.3.7.mod_conv1.style_weight', 'model.encoders.3.7.mod_conv1.style_bias', 'model.encoders.3.7.mod_conv1.weight', 'model.encoders.3.7.mod_conv1.bias', 'model.encoders.3.7.mod_conv2.style_weight', 'model.encoders.3.7.mod_conv2.style_bias', 'model.encoders.3.7.mod_conv2.weight', 'model.encoders.3.7.mod_conv2.bias', 'model.encoders.3.7.mod_conv3.style_weight', 'model.encoders.3.7.mod_conv3.style_bias', 'model.encoders.3.7.mod_conv3.weight', 'model.encoders.3.7.mod_conv3.bias', 'model.encoders.3.7.sca_conv.style_weight', 'model.encoders.3.7.sca_conv.style_bias', 'model.encoders.3.7.sca_conv.weight', 'model.encoders.3.7.sca_conv.bias', 'model.encoders.3.7.mod_conv4.style_weight', 'model.encoders.3.7.mod_conv4.style_bias', 'model.encoders.3.7.mod_conv4.weight', 'model.encoders.3.7.mod_conv4.bias', 'model.encoders.3.7.mod_conv5.style_weight', 'model.encoders.3.7.mod_conv5.style_bias', 'model.encoders.3.7.mod_conv5.weight', 'model.encoders.3.7.mod_conv5.bias', 'model.decoders.0.0.mod_conv1.style_weight', 'model.decoders.0.0.mod_conv1.style_bias', 'model.decoders.0.0.mod_conv1.weight', 'model.decoders.0.0.mod_conv1.bias', 'model.decoders.0.0.mod_conv2.style_weight', 'model.decoders.0.0.mod_conv2.style_bias', 'model.decoders.0.0.mod_conv2.weight', 'model.decoders.0.0.mod_conv2.bias', 'model.decoders.0.0.mod_conv3.style_weight', 'model.decoders.0.0.mod_conv3.style_bias', 'model.decoders.0.0.mod_conv3.weight', 'model.decoders.0.0.mod_conv3.bias', 'model.decoders.0.0.sca_conv.style_weight', 'model.decoders.0.0.sca_conv.style_bias', 'model.decoders.0.0.sca_conv.weight', 'model.decoders.0.0.sca_conv.bias', 'model.decoders.0.0.mod_conv4.style_weight', 'model.decoders.0.0.mod_conv4.style_bias', 'model.decoders.0.0.mod_conv4.weight', 'model.decoders.0.0.mod_conv4.bias', 'model.decoders.0.0.mod_conv5.style_weight', 'model.decoders.0.0.mod_conv5.style_bias', 'model.decoders.0.0.mod_conv5.weight', 'model.decoders.0.0.mod_conv5.bias', 'model.decoders.0.1.mod_conv1.style_weight', 'model.decoders.0.1.mod_conv1.style_bias', 'model.decoders.0.1.mod_conv1.weight', 'model.decoders.0.1.mod_conv1.bias', 'model.decoders.0.1.mod_conv2.style_weight', 'model.decoders.0.1.mod_conv2.style_bias', 'model.decoders.0.1.mod_conv2.weight', 'model.decoders.0.1.mod_conv2.bias', 'model.decoders.0.1.mod_conv3.style_weight', 'model.decoders.0.1.mod_conv3.style_bias', 'model.decoders.0.1.mod_conv3.weight', 'model.decoders.0.1.mod_conv3.bias', 'model.decoders.0.1.sca_conv.style_weight', 'model.decoders.0.1.sca_conv.style_bias', 'model.decoders.0.1.sca_conv.weight', 'model.decoders.0.1.sca_conv.bias', 'model.decoders.0.1.mod_conv4.style_weight', 'model.decoders.0.1.mod_conv4.style_bias', 'model.decoders.0.1.mod_conv4.weight', 'model.decoders.0.1.mod_conv4.bias', 'model.decoders.0.1.mod_conv5.style_weight', 'model.decoders.0.1.mod_conv5.style_bias', 'model.decoders.0.1.mod_conv5.weight', 'model.decoders.0.1.mod_conv5.bias', 'model.decoders.1.0.mod_conv1.style_weight', 'model.decoders.1.0.mod_conv1.style_bias', 'model.decoders.1.0.mod_conv1.weight', 'model.decoders.1.0.mod_conv1.bias', 'model.decoders.1.0.mod_conv2.style_weight', 'model.decoders.1.0.mod_conv2.style_bias', 'model.decoders.1.0.mod_conv2.weight', 'model.decoders.1.0.mod_conv2.bias', 'model.decoders.1.0.mod_conv3.style_weight', 'model.decoders.1.0.mod_conv3.style_bias', 'model.decoders.1.0.mod_conv3.weight', 'model.decoders.1.0.mod_conv3.bias', 'model.decoders.1.0.sca_conv.style_weight', 'model.decoders.1.0.sca_conv.style_bias', 'model.decoders.1.0.sca_conv.weight', 'model.decoders.1.0.sca_conv.bias', 'model.decoders.1.0.mod_conv4.style_weight', 'model.decoders.1.0.mod_conv4.style_bias', 'model.decoders.1.0.mod_conv4.weight', 'model.decoders.1.0.mod_conv4.bias', 'model.decoders.1.0.mod_conv5.style_weight', 'model.decoders.1.0.mod_conv5.style_bias', 'model.decoders.1.0.mod_conv5.weight', 'model.decoders.1.0.mod_conv5.bias', 'model.decoders.1.1.mod_conv1.style_weight', 'model.decoders.1.1.mod_conv1.style_bias', 'model.decoders.1.1.mod_conv1.weight', 'model.decoders.1.1.mod_conv1.bias', 'model.decoders.1.1.mod_conv2.style_weight', 'model.decoders.1.1.mod_conv2.style_bias', 'model.decoders.1.1.mod_conv2.weight', 'model.decoders.1.1.mod_conv2.bias', 'model.decoders.1.1.mod_conv3.style_weight', 'model.decoders.1.1.mod_conv3.style_bias', 'model.decoders.1.1.mod_conv3.weight', 'model.decoders.1.1.mod_conv3.bias', 'model.decoders.1.1.sca_conv.style_weight', 'model.decoders.1.1.sca_conv.style_bias', 'model.decoders.1.1.sca_conv.weight', 'model.decoders.1.1.sca_conv.bias', 'model.decoders.1.1.mod_conv4.style_weight', 'model.decoders.1.1.mod_conv4.style_bias', 'model.decoders.1.1.mod_conv4.weight', 'model.decoders.1.1.mod_conv4.bias', 'model.decoders.1.1.mod_conv5.style_weight', 'model.decoders.1.1.mod_conv5.style_bias', 'model.decoders.1.1.mod_conv5.weight', 'model.decoders.1.1.mod_conv5.bias', 'model.decoders.2.0.mod_conv1.style_weight', 'model.decoders.2.0.mod_conv1.style_bias', 'model.decoders.2.0.mod_conv1.weight', 'model.decoders.2.0.mod_conv1.bias', 'model.decoders.2.0.mod_conv2.style_weight', 'model.decoders.2.0.mod_conv2.style_bias', 'model.decoders.2.0.mod_conv2.weight', 'model.decoders.2.0.mod_conv2.bias', 'model.decoders.2.0.mod_conv3.style_weight', 'model.decoders.2.0.mod_conv3.style_bias', 'model.decoders.2.0.mod_conv3.weight', 'model.decoders.2.0.mod_conv3.bias', 'model.decoders.2.0.sca_conv.style_weight', 'model.decoders.2.0.sca_conv.style_bias', 'model.decoders.2.0.sca_conv.weight', 'model.decoders.2.0.sca_conv.bias', 'model.decoders.2.0.mod_conv4.style_weight', 'model.decoders.2.0.mod_conv4.style_bias', 'model.decoders.2.0.mod_conv4.weight', 'model.decoders.2.0.mod_conv4.bias', 'model.decoders.2.0.mod_conv5.style_weight', 'model.decoders.2.0.mod_conv5.style_bias', 'model.decoders.2.0.mod_conv5.weight', 'model.decoders.2.0.mod_conv5.bias', 'model.decoders.2.1.mod_conv1.style_weight', 'model.decoders.2.1.mod_conv1.style_bias', 'model.decoders.2.1.mod_conv1.weight', 'model.decoders.2.1.mod_conv1.bias', 'model.decoders.2.1.mod_conv2.style_weight', 'model.decoders.2.1.mod_conv2.style_bias', 'model.decoders.2.1.mod_conv2.weight', 'model.decoders.2.1.mod_conv2.bias', 'model.decoders.2.1.mod_conv3.style_weight', 'model.decoders.2.1.mod_conv3.style_bias', 'model.decoders.2.1.mod_conv3.weight', 'model.decoders.2.1.mod_conv3.bias', 'model.decoders.2.1.sca_conv.style_weight', 'model.decoders.2.1.sca_conv.style_bias', 'model.decoders.2.1.sca_conv.weight', 'model.decoders.2.1.sca_conv.bias', 'model.decoders.2.1.mod_conv4.style_weight', 'model.decoders.2.1.mod_conv4.style_bias', 'model.decoders.2.1.mod_conv4.weight', 'model.decoders.2.1.mod_conv4.bias', 'model.decoders.2.1.mod_conv5.style_weight', 'model.decoders.2.1.mod_conv5.style_bias', 'model.decoders.2.1.mod_conv5.weight', 'model.decoders.2.1.mod_conv5.bias', 'model.decoders.3.0.mod_conv1.style_weight', 'model.decoders.3.0.mod_conv1.style_bias', 'model.decoders.3.0.mod_conv1.weight', 'model.decoders.3.0.mod_conv1.bias', 'model.decoders.3.0.mod_conv2.style_weight', 'model.decoders.3.0.mod_conv2.style_bias', 'model.decoders.3.0.mod_conv2.weight', 'model.decoders.3.0.mod_conv2.bias', 'model.decoders.3.0.mod_conv3.style_weight', 'model.decoders.3.0.mod_conv3.style_bias', 'model.decoders.3.0.mod_conv3.weight', 'model.decoders.3.0.mod_conv3.bias', 'model.decoders.3.0.sca_conv.style_weight', 'model.decoders.3.0.sca_conv.style_bias', 'model.decoders.3.0.sca_conv.weight', 'model.decoders.3.0.sca_conv.bias', 'model.decoders.3.0.mod_conv4.style_weight', 'model.decoders.3.0.mod_conv4.style_bias', 'model.decoders.3.0.mod_conv4.weight', 'model.decoders.3.0.mod_conv4.bias', 'model.decoders.3.0.mod_conv5.style_weight', 'model.decoders.3.0.mod_conv5.style_bias', 'model.decoders.3.0.mod_conv5.weight', 'model.decoders.3.0.mod_conv5.bias', 'model.decoders.3.1.mod_conv1.style_weight', 'model.decoders.3.1.mod_conv1.style_bias', 'model.decoders.3.1.mod_conv1.weight', 'model.decoders.3.1.mod_conv1.bias', 'model.decoders.3.1.mod_conv2.style_weight', 'model.decoders.3.1.mod_conv2.style_bias', 'model.decoders.3.1.mod_conv2.weight', 'model.decoders.3.1.mod_conv2.bias', 'model.decoders.3.1.mod_conv3.style_weight', 'model.decoders.3.1.mod_conv3.style_bias', 'model.decoders.3.1.mod_conv3.weight', 'model.decoders.3.1.mod_conv3.bias', 'model.decoders.3.1.sca_conv.style_weight', 'model.decoders.3.1.sca_conv.style_bias', 'model.decoders.3.1.sca_conv.weight', 'model.decoders.3.1.sca_conv.bias', 'model.decoders.3.1.mod_conv4.style_weight', 'model.decoders.3.1.mod_conv4.style_bias', 'model.decoders.3.1.mod_conv4.weight', 'model.decoders.3.1.mod_conv4.bias', 'model.decoders.3.1.mod_conv5.style_weight', 'model.decoders.3.1.mod_conv5.style_bias', 'model.decoders.3.1.mod_conv5.weight', 'model.decoders.3.1.mod_conv5.bias', 'model.ups_convs.0.weight', 'model.ups_convs.1.weight', 'model.ups_convs.2.weight', 'model.ups_convs.3.weight', 'model.middle_blks_seq.0.beta', 'model.middle_blks_seq.0.gamma', 'model.middle_blks_seq.0.mod_conv1.style_weight', 'model.middle_blks_seq.0.mod_conv1.style_bias', 'model.middle_blks_seq.0.mod_conv1.weight', 'model.middle_blks_seq.0.mod_conv1.bias', 'model.middle_blks_seq.0.mod_conv2.style_weight', 'model.middle_blks_seq.0.mod_conv2.style_bias', 'model.middle_blks_seq.0.mod_conv2.weight', 'model.middle_blks_seq.0.mod_conv2.bias', 'model.middle_blks_seq.0.mod_conv3.style_weight', 'model.middle_blks_seq.0.mod_conv3.style_bias', 'model.middle_blks_seq.0.mod_conv3.weight', 'model.middle_blks_seq.0.mod_conv3.bias', 'model.middle_blks_seq.0.sca_conv.style_weight', 'model.middle_blks_seq.0.sca_conv.style_bias', 'model.middle_blks_seq.0.sca_conv.weight', 'model.middle_blks_seq.0.sca_conv.bias', 'model.middle_blks_seq.0.mod_conv4.style_weight', 'model.middle_blks_seq.0.mod_conv4.style_bias', 'model.middle_blks_seq.0.mod_conv4.weight', 'model.middle_blks_seq.0.mod_conv4.bias', 'model.middle_blks_seq.0.mod_conv5.style_weight', 'model.middle_blks_seq.0.mod_conv5.style_bias', 'model.middle_blks_seq.0.mod_conv5.weight', 'model.middle_blks_seq.0.mod_conv5.bias', 'model.middle_blks_seq.0.norm1.weight', 'model.middle_blks_seq.0.norm1.bias', 'model.middle_blks_seq.0.norm2.weight', 'model.middle_blks_seq.0.norm2.bias', 'model.middle_blks_seq.1.beta', 'model.middle_blks_seq.1.gamma', 'model.middle_blks_seq.1.mod_conv1.style_weight', 'model.middle_blks_seq.1.mod_conv1.style_bias', 'model.middle_blks_seq.1.mod_conv1.weight', 'model.middle_blks_seq.1.mod_conv1.bias', 'model.middle_blks_seq.1.mod_conv2.style_weight', 'model.middle_blks_seq.1.mod_conv2.style_bias', 'model.middle_blks_seq.1.mod_conv2.weight', 'model.middle_blks_seq.1.mod_conv2.bias', 'model.middle_blks_seq.1.mod_conv3.style_weight', 'model.middle_blks_seq.1.mod_conv3.style_bias', 'model.middle_blks_seq.1.mod_conv3.weight', 'model.middle_blks_seq.1.mod_conv3.bias', 'model.middle_blks_seq.1.sca_conv.style_weight', 'model.middle_blks_seq.1.sca_conv.style_bias', 'model.middle_blks_seq.1.sca_conv.weight', 'model.middle_blks_seq.1.sca_conv.bias', 'model.middle_blks_seq.1.mod_conv4.style_weight', 'model.middle_blks_seq.1.mod_conv4.style_bias', 'model.middle_blks_seq.1.mod_conv4.weight', 'model.middle_blks_seq.1.mod_conv4.bias', 'model.middle_blks_seq.1.mod_conv5.style_weight', 'model.middle_blks_seq.1.mod_conv5.style_bias', 'model.middle_blks_seq.1.mod_conv5.weight', 'model.middle_blks_seq.1.mod_conv5.bias', 'model.middle_blks_seq.1.norm1.weight', 'model.middle_blks_seq.1.norm1.bias', 'model.middle_blks_seq.1.norm2.weight', 'model.middle_blks_seq.1.norm2.bias', 'model.middle_blks_seq.2.beta', 'model.middle_blks_seq.2.gamma', 'model.middle_blks_seq.2.mod_conv1.style_weight', 'model.middle_blks_seq.2.mod_conv1.style_bias', 'model.middle_blks_seq.2.mod_conv1.weight', 'model.middle_blks_seq.2.mod_conv1.bias', 'model.middle_blks_seq.2.mod_conv2.style_weight', 'model.middle_blks_seq.2.mod_conv2.style_bias', 'model.middle_blks_seq.2.mod_conv2.weight', 'model.middle_blks_seq.2.mod_conv2.bias', 'model.middle_blks_seq.2.mod_conv3.style_weight', 'model.middle_blks_seq.2.mod_conv3.style_bias', 'model.middle_blks_seq.2.mod_conv3.weight', 'model.middle_blks_seq.2.mod_conv3.bias', 'model.middle_blks_seq.2.sca_conv.style_weight', 'model.middle_blks_seq.2.sca_conv.style_bias', 'model.middle_blks_seq.2.sca_conv.weight', 'model.middle_blks_seq.2.sca_conv.bias', 'model.middle_blks_seq.2.mod_conv4.style_weight', 'model.middle_blks_seq.2.mod_conv4.style_bias', 'model.middle_blks_seq.2.mod_conv4.weight', 'model.middle_blks_seq.2.mod_conv4.bias', 'model.middle_blks_seq.2.mod_conv5.style_weight', 'model.middle_blks_seq.2.mod_conv5.style_bias', 'model.middle_blks_seq.2.mod_conv5.weight', 'model.middle_blks_seq.2.mod_conv5.bias', 'model.middle_blks_seq.2.norm1.weight', 'model.middle_blks_seq.2.norm1.bias', 'model.middle_blks_seq.2.norm2.weight', 'model.middle_blks_seq.2.norm2.bias', 'model.middle_blks_seq.3.beta', 'model.middle_blks_seq.3.gamma', 'model.middle_blks_seq.3.mod_conv1.style_weight', 'model.middle_blks_seq.3.mod_conv1.style_bias', 'model.middle_blks_seq.3.mod_conv1.weight', 'model.middle_blks_seq.3.mod_conv1.bias', 'model.middle_blks_seq.3.mod_conv2.style_weight', 'model.middle_blks_seq.3.mod_conv2.style_bias', 'model.middle_blks_seq.3.mod_conv2.weight', 'model.middle_blks_seq.3.mod_conv2.bias', 'model.middle_blks_seq.3.mod_conv3.style_weight', 'model.middle_blks_seq.3.mod_conv3.style_bias', 'model.middle_blks_seq.3.mod_conv3.weight', 'model.middle_blks_seq.3.mod_conv3.bias', 'model.middle_blks_seq.3.sca_conv.style_weight', 'model.middle_blks_seq.3.sca_conv.style_bias', 'model.middle_blks_seq.3.sca_conv.weight', 'model.middle_blks_seq.3.sca_conv.bias', 'model.middle_blks_seq.3.mod_conv4.style_weight', 'model.middle_blks_seq.3.mod_conv4.style_bias', 'model.middle_blks_seq.3.mod_conv4.weight', 'model.middle_blks_seq.3.mod_conv4.bias', 'model.middle_blks_seq.3.mod_conv5.style_weight', 'model.middle_blks_seq.3.mod_conv5.style_bias', 'model.middle_blks_seq.3.mod_conv5.weight', 'model.middle_blks_seq.3.mod_conv5.bias', 'model.middle_blks_seq.3.norm1.weight', 'model.middle_blks_seq.3.norm1.bias', 'model.middle_blks_seq.3.norm2.weight', 'model.middle_blks_seq.3.norm2.bias'], unexpected_keys=['model.ups.0.0.weight', 'model.ups.1.0.weight', 'model.ups.2.0.weight', 'model.ups.3.0.weight', 'model.encoders.0.0.conv1.weight', 'model.encoders.0.0.conv1.bias', 'model.encoders.0.0.conv2.weight', 'model.encoders.0.0.conv2.bias', 'model.encoders.0.0.conv3.weight', 'model.encoders.0.0.conv3.bias', 'model.encoders.0.0.sca.1.weight', 'model.encoders.0.0.sca.1.bias', 'model.encoders.0.0.conv4.weight', 'model.encoders.0.0.conv4.bias', 'model.encoders.0.0.conv5.weight', 'model.encoders.0.0.conv5.bias', 'model.encoders.0.1.conv1.weight', 'model.encoders.0.1.conv1.bias', 'model.encoders.0.1.conv2.weight', 'model.encoders.0.1.conv2.bias', 'model.encoders.0.1.conv3.weight', 'model.encoders.0.1.conv3.bias', 'model.encoders.0.1.sca.1.weight', 'model.encoders.0.1.sca.1.bias', 'model.encoders.0.1.conv4.weight', 'model.encoders.0.1.conv4.bias', 'model.encoders.0.1.conv5.weight', 'model.encoders.0.1.conv5.bias', 'model.encoders.1.0.conv1.weight', 'model.encoders.1.0.conv1.bias', 'model.encoders.1.0.conv2.weight', 'model.encoders.1.0.conv2.bias', 'model.encoders.1.0.conv3.weight', 'model.encoders.1.0.conv3.bias', 'model.encoders.1.0.sca.1.weight', 'model.encoders.1.0.sca.1.bias', 'model.encoders.1.0.conv4.weight', 'model.encoders.1.0.conv4.bias', 'model.encoders.1.0.conv5.weight', 'model.encoders.1.0.conv5.bias', 'model.encoders.1.1.conv1.weight', 'model.encoders.1.1.conv1.bias', 'model.encoders.1.1.conv2.weight', 'model.encoders.1.1.conv2.bias', 'model.encoders.1.1.conv3.weight', 'model.encoders.1.1.conv3.bias', 'model.encoders.1.1.sca.1.weight', 'model.encoders.1.1.sca.1.bias', 'model.encoders.1.1.conv4.weight', 'model.encoders.1.1.conv4.bias', 'model.encoders.1.1.conv5.weight', 'model.encoders.1.1.conv5.bias', 'model.encoders.2.0.conv1.weight', 'model.encoders.2.0.conv1.bias', 'model.encoders.2.0.conv2.weight', 'model.encoders.2.0.conv2.bias', 'model.encoders.2.0.conv3.weight', 'model.encoders.2.0.conv3.bias', 'model.encoders.2.0.sca.1.weight', 'model.encoders.2.0.sca.1.bias', 'model.encoders.2.0.conv4.weight', 'model.encoders.2.0.conv4.bias', 'model.encoders.2.0.conv5.weight', 'model.encoders.2.0.conv5.bias', 'model.encoders.2.1.conv1.weight', 'model.encoders.2.1.conv1.bias', 'model.encoders.2.1.conv2.weight', 'model.encoders.2.1.conv2.bias', 'model.encoders.2.1.conv3.weight', 'model.encoders.2.1.conv3.bias', 'model.encoders.2.1.sca.1.weight', 'model.encoders.2.1.sca.1.bias', 'model.encoders.2.1.conv4.weight', 'model.encoders.2.1.conv4.bias', 'model.encoders.2.1.conv5.weight', 'model.encoders.2.1.conv5.bias', 'model.encoders.2.2.conv1.weight', 'model.encoders.2.2.conv1.bias', 'model.encoders.2.2.conv2.weight', 'model.encoders.2.2.conv2.bias', 'model.encoders.2.2.conv3.weight', 'model.encoders.2.2.conv3.bias', 'model.encoders.2.2.sca.1.weight', 'model.encoders.2.2.sca.1.bias', 'model.encoders.2.2.conv4.weight', 'model.encoders.2.2.conv4.bias', 'model.encoders.2.2.conv5.weight', 'model.encoders.2.2.conv5.bias', 'model.encoders.2.3.conv1.weight', 'model.encoders.2.3.conv1.bias', 'model.encoders.2.3.conv2.weight', 'model.encoders.2.3.conv2.bias', 'model.encoders.2.3.conv3.weight', 'model.encoders.2.3.conv3.bias', 'model.encoders.2.3.sca.1.weight', 'model.encoders.2.3.sca.1.bias', 'model.encoders.2.3.conv4.weight', 'model.encoders.2.3.conv4.bias', 'model.encoders.2.3.conv5.weight', 'model.encoders.2.3.conv5.bias', 'model.encoders.3.0.conv1.weight', 'model.encoders.3.0.conv1.bias', 'model.encoders.3.0.conv2.weight', 'model.encoders.3.0.conv2.bias', 'model.encoders.3.0.conv3.weight', 'model.encoders.3.0.conv3.bias', 'model.encoders.3.0.sca.1.weight', 'model.encoders.3.0.sca.1.bias', 'model.encoders.3.0.conv4.weight', 'model.encoders.3.0.conv4.bias', 'model.encoders.3.0.conv5.weight', 'model.encoders.3.0.conv5.bias', 'model.encoders.3.1.conv1.weight', 'model.encoders.3.1.conv1.bias', 'model.encoders.3.1.conv2.weight', 'model.encoders.3.1.conv2.bias', 'model.encoders.3.1.conv3.weight', 'model.encoders.3.1.conv3.bias', 'model.encoders.3.1.sca.1.weight', 'model.encoders.3.1.sca.1.bias', 'model.encoders.3.1.conv4.weight', 'model.encoders.3.1.conv4.bias', 'model.encoders.3.1.conv5.weight', 'model.encoders.3.1.conv5.bias', 'model.encoders.3.2.conv1.weight', 'model.encoders.3.2.conv1.bias', 'model.encoders.3.2.conv2.weight', 'model.encoders.3.2.conv2.bias', 'model.encoders.3.2.conv3.weight', 'model.encoders.3.2.conv3.bias', 'model.encoders.3.2.sca.1.weight', 'model.encoders.3.2.sca.1.bias', 'model.encoders.3.2.conv4.weight', 'model.encoders.3.2.conv4.bias', 'model.encoders.3.2.conv5.weight', 'model.encoders.3.2.conv5.bias', 'model.encoders.3.3.conv1.weight', 'model.encoders.3.3.conv1.bias', 'model.encoders.3.3.conv2.weight', 'model.encoders.3.3.conv2.bias', 'model.encoders.3.3.conv3.weight', 'model.encoders.3.3.conv3.bias', 'model.encoders.3.3.sca.1.weight', 'model.encoders.3.3.sca.1.bias', 'model.encoders.3.3.conv4.weight', 'model.encoders.3.3.conv4.bias', 'model.encoders.3.3.conv5.weight', 'model.encoders.3.3.conv5.bias', 'model.encoders.3.4.conv1.weight', 'model.encoders.3.4.conv1.bias', 'model.encoders.3.4.conv2.weight', 'model.encoders.3.4.conv2.bias', 'model.encoders.3.4.conv3.weight', 'model.encoders.3.4.conv3.bias', 'model.encoders.3.4.sca.1.weight', 'model.encoders.3.4.sca.1.bias', 'model.encoders.3.4.conv4.weight', 'model.encoders.3.4.conv4.bias', 'model.encoders.3.4.conv5.weight', 'model.encoders.3.4.conv5.bias', 'model.encoders.3.5.conv1.weight', 'model.encoders.3.5.conv1.bias', 'model.encoders.3.5.conv2.weight', 'model.encoders.3.5.conv2.bias', 'model.encoders.3.5.conv3.weight', 'model.encoders.3.5.conv3.bias', 'model.encoders.3.5.sca.1.weight', 'model.encoders.3.5.sca.1.bias', 'model.encoders.3.5.conv4.weight', 'model.encoders.3.5.conv4.bias', 'model.encoders.3.5.conv5.weight', 'model.encoders.3.5.conv5.bias', 'model.encoders.3.6.conv1.weight', 'model.encoders.3.6.conv1.bias', 'model.encoders.3.6.conv2.weight', 'model.encoders.3.6.conv2.bias', 'model.encoders.3.6.conv3.weight', 'model.encoders.3.6.conv3.bias', 'model.encoders.3.6.sca.1.weight', 'model.encoders.3.6.sca.1.bias', 'model.encoders.3.6.conv4.weight', 'model.encoders.3.6.conv4.bias', 'model.encoders.3.6.conv5.weight', 'model.encoders.3.6.conv5.bias', 'model.encoders.3.7.conv1.weight', 'model.encoders.3.7.conv1.bias', 'model.encoders.3.7.conv2.weight', 'model.encoders.3.7.conv2.bias', 'model.encoders.3.7.conv3.weight', 'model.encoders.3.7.conv3.bias', 'model.encoders.3.7.sca.1.weight', 'model.encoders.3.7.sca.1.bias', 'model.encoders.3.7.conv4.weight', 'model.encoders.3.7.conv4.bias', 'model.encoders.3.7.conv5.weight', 'model.encoders.3.7.conv5.bias', 'model.decoders.0.0.conv1.weight', 'model.decoders.0.0.conv1.bias', 'model.decoders.0.0.conv2.weight', 'model.decoders.0.0.conv2.bias', 'model.decoders.0.0.conv3.weight', 'model.decoders.0.0.conv3.bias', 'model.decoders.0.0.sca.1.weight', 'model.decoders.0.0.sca.1.bias', 'model.decoders.0.0.conv4.weight', 'model.decoders.0.0.conv4.bias', 'model.decoders.0.0.conv5.weight', 'model.decoders.0.0.conv5.bias', 'model.decoders.0.1.conv1.weight', 'model.decoders.0.1.conv1.bias', 'model.decoders.0.1.conv2.weight', 'model.decoders.0.1.conv2.bias', 'model.decoders.0.1.conv3.weight', 'model.decoders.0.1.conv3.bias', 'model.decoders.0.1.sca.1.weight', 'model.decoders.0.1.sca.1.bias', 'model.decoders.0.1.conv4.weight', 'model.decoders.0.1.conv4.bias', 'model.decoders.0.1.conv5.weight', 'model.decoders.0.1.conv5.bias', 'model.decoders.1.0.conv1.weight', 'model.decoders.1.0.conv1.bias', 'model.decoders.1.0.conv2.weight', 'model.decoders.1.0.conv2.bias', 'model.decoders.1.0.conv3.weight', 'model.decoders.1.0.conv3.bias', 'model.decoders.1.0.sca.1.weight', 'model.decoders.1.0.sca.1.bias', 'model.decoders.1.0.conv4.weight', 'model.decoders.1.0.conv4.bias', 'model.decoders.1.0.conv5.weight', 'model.decoders.1.0.conv5.bias', 'model.decoders.1.1.conv1.weight', 'model.decoders.1.1.conv1.bias', 'model.decoders.1.1.conv2.weight', 'model.decoders.1.1.conv2.bias', 'model.decoders.1.1.conv3.weight', 'model.decoders.1.1.conv3.bias', 'model.decoders.1.1.sca.1.weight', 'model.decoders.1.1.sca.1.bias', 'model.decoders.1.1.conv4.weight', 'model.decoders.1.1.conv4.bias', 'model.decoders.1.1.conv5.weight', 'model.decoders.1.1.conv5.bias', 'model.decoders.2.0.conv1.weight', 'model.decoders.2.0.conv1.bias', 'model.decoders.2.0.conv2.weight', 'model.decoders.2.0.conv2.bias', 'model.decoders.2.0.conv3.weight', 'model.decoders.2.0.conv3.bias', 'model.decoders.2.0.sca.1.weight', 'model.decoders.2.0.sca.1.bias', 'model.decoders.2.0.conv4.weight', 'model.decoders.2.0.conv4.bias', 'model.decoders.2.0.conv5.weight', 'model.decoders.2.0.conv5.bias', 'model.decoders.2.1.conv1.weight', 'model.decoders.2.1.conv1.bias', 'model.decoders.2.1.conv2.weight', 'model.decoders.2.1.conv2.bias', 'model.decoders.2.1.conv3.weight', 'model.decoders.2.1.conv3.bias', 'model.decoders.2.1.sca.1.weight', 'model.decoders.2.1.sca.1.bias', 'model.decoders.2.1.conv4.weight', 'model.decoders.2.1.conv4.bias', 'model.decoders.2.1.conv5.weight', 'model.decoders.2.1.conv5.bias', 'model.decoders.3.0.conv1.weight', 'model.decoders.3.0.conv1.bias', 'model.decoders.3.0.conv2.weight', 'model.decoders.3.0.conv2.bias', 'model.decoders.3.0.conv3.weight', 'model.decoders.3.0.conv3.bias', 'model.decoders.3.0.sca.1.weight', 'model.decoders.3.0.sca.1.bias', 'model.decoders.3.0.conv4.weight', 'model.decoders.3.0.conv4.bias', 'model.decoders.3.0.conv5.weight', 'model.decoders.3.0.conv5.bias', 'model.decoders.3.1.conv1.weight', 'model.decoders.3.1.conv1.bias', 'model.decoders.3.1.conv2.weight', 'model.decoders.3.1.conv2.bias', 'model.decoders.3.1.conv3.weight', 'model.decoders.3.1.conv3.bias', 'model.decoders.3.1.sca.1.weight', 'model.decoders.3.1.sca.1.bias', 'model.decoders.3.1.conv4.weight', 'model.decoders.3.1.conv4.bias', 'model.decoders.3.1.conv5.weight', 'model.decoders.3.1.conv5.bias', 'model.middle_blks.0.beta', 'model.middle_blks.0.gamma', 'model.middle_blks.0.conv1.weight', 'model.middle_blks.0.conv1.bias', 'model.middle_blks.0.conv2.weight', 'model.middle_blks.0.conv2.bias', 'model.middle_blks.0.conv3.weight', 'model.middle_blks.0.conv3.bias', 'model.middle_blks.0.sca.1.weight', 'model.middle_blks.0.sca.1.bias', 'model.middle_blks.0.conv4.weight', 'model.middle_blks.0.conv4.bias', 'model.middle_blks.0.conv5.weight', 'model.middle_blks.0.conv5.bias', 'model.middle_blks.0.norm1.weight', 'model.middle_blks.0.norm1.bias', 'model.middle_blks.0.norm2.weight', 'model.middle_blks.0.norm2.bias', 'model.middle_blks.1.beta', 'model.middle_blks.1.gamma', 'model.middle_blks.1.conv1.weight', 'model.middle_blks.1.conv1.bias', 'model.middle_blks.1.conv2.weight', 'model.middle_blks.1.conv2.bias', 'model.middle_blks.1.conv3.weight', 'model.middle_blks.1.conv3.bias', 'model.middle_blks.1.sca.1.weight', 'model.middle_blks.1.sca.1.bias', 'model.middle_blks.1.conv4.weight', 'model.middle_blks.1.conv4.bias', 'model.middle_blks.1.conv5.weight', 'model.middle_blks.1.conv5.bias', 'model.middle_blks.1.norm1.weight', 'model.middle_blks.1.norm1.bias', 'model.middle_blks.1.norm2.weight', 'model.middle_blks.1.norm2.bias', 'model.middle_blks.2.beta', 'model.middle_blks.2.gamma', 'model.middle_blks.2.conv1.weight', 'model.middle_blks.2.conv1.bias', 'model.middle_blks.2.conv2.weight', 'model.middle_blks.2.conv2.bias', 'model.middle_blks.2.conv3.weight', 'model.middle_blks.2.conv3.bias', 'model.middle_blks.2.sca.1.weight', 'model.middle_blks.2.sca.1.bias', 'model.middle_blks.2.conv4.weight', 'model.middle_blks.2.conv4.bias', 'model.middle_blks.2.conv5.weight', 'model.middle_blks.2.conv5.bias', 'model.middle_blks.2.norm1.weight', 'model.middle_blks.2.norm1.bias', 'model.middle_blks.2.norm2.weight', 'model.middle_blks.2.norm2.bias', 'model.middle_blks.3.beta', 'model.middle_blks.3.gamma', 'model.middle_blks.3.conv1.weight', 'model.middle_blks.3.conv1.bias', 'model.middle_blks.3.conv2.weight', 'model.middle_blks.3.conv2.bias', 'model.middle_blks.3.conv3.weight', 'model.middle_blks.3.conv3.bias', 'model.middle_blks.3.sca.1.weight', 'model.middle_blks.3.sca.1.bias', 'model.middle_blks.3.conv4.weight', 'model.middle_blks.3.conv4.bias', 'model.middle_blks.3.conv5.weight', 'model.middle_blks.3.conv5.bias', 'model.middle_blks.3.norm1.weight', 'model.middle_blks.3.norm1.bias', 'model.middle_blks.3.norm2.weight', 'model.middle_blks.3.norm2.bias'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pt_ckpt = torch.load(\"/home/user/ckwan1/ml_project/field2field/new_checkpoints/naf_base_sca_denoise_32/best-checkpoint-epoch=2303_c.ckpt\", map_location=\"cpu\")\n",
    "pre_model = Lpt2NbodyNetLightning(**config1['model'])\n",
    "\n",
    "pre_model.load_state_dict(pt_ckpt['state_dict'],strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Weight unchanged: model.intro.weight\n",
      "✅ Weight unchanged: model.intro.bias\n",
      "✅ Weight unchanged: model.encoders.0.0.beta\n",
      "✅ Weight unchanged: model.encoders.0.0.gamma\n",
      "❌ Weight changed: model.encoders.0.0.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.0.0.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.0.0.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.0.0.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.0.0.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.0.0.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.0.0.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.0.0.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.0.0.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.0.0.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.0.0.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.0.0.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.0.0.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.0.0.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.0.0.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.0.0.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.0.1.beta\n",
      "✅ Weight unchanged: model.encoders.0.1.gamma\n",
      "❌ Weight changed: model.encoders.0.1.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.0.1.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.0.1.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.0.1.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.0.1.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.0.1.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.0.1.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.0.1.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.0.1.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.0.1.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.0.1.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.0.1.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.0.1.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.0.1.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.0.1.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.0.1.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.1.0.beta\n",
      "✅ Weight unchanged: model.encoders.1.0.gamma\n",
      "❌ Weight changed: model.encoders.1.0.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.1.0.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.1.0.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.1.0.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.1.0.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.1.0.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.1.0.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.1.0.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.1.0.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.1.0.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.1.0.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.1.0.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.1.0.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.1.0.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.1.0.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.1.0.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.1.1.beta\n",
      "✅ Weight unchanged: model.encoders.1.1.gamma\n",
      "❌ Weight changed: model.encoders.1.1.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.1.1.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.1.1.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.1.1.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.1.1.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.1.1.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.1.1.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.1.1.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.1.1.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.1.1.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.1.1.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.1.1.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.1.1.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.1.1.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.1.1.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.1.1.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.2.0.beta\n",
      "✅ Weight unchanged: model.encoders.2.0.gamma\n",
      "❌ Weight changed: model.encoders.2.0.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.2.0.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.2.0.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.2.0.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.2.0.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.2.0.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.2.0.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.2.0.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.2.0.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.2.0.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.2.0.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.2.0.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.2.0.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.2.0.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.2.0.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.2.0.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.2.1.beta\n",
      "✅ Weight unchanged: model.encoders.2.1.gamma\n",
      "❌ Weight changed: model.encoders.2.1.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.2.1.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.2.1.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.2.1.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.2.1.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.2.1.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.2.1.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.2.1.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.2.1.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.2.1.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.2.1.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.2.1.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.2.1.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.2.1.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.2.1.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.2.1.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.2.2.beta\n",
      "✅ Weight unchanged: model.encoders.2.2.gamma\n",
      "❌ Weight changed: model.encoders.2.2.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.2.2.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.2.2.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.2.2.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.2.2.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.2.2.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.2.2.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.2.2.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.2.2.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.2.2.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.2.2.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.2.2.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.2.2.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.2.2.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.2.2.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.2.2.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.2.3.beta\n",
      "✅ Weight unchanged: model.encoders.2.3.gamma\n",
      "❌ Weight changed: model.encoders.2.3.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.2.3.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.2.3.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.2.3.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.2.3.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.2.3.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.2.3.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.2.3.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.2.3.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.2.3.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.2.3.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.2.3.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.2.3.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.2.3.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.2.3.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.2.3.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.3.0.beta\n",
      "✅ Weight unchanged: model.encoders.3.0.gamma\n",
      "❌ Weight changed: model.encoders.3.0.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.3.0.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.3.0.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.3.0.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.3.0.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.3.0.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.3.0.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.3.0.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.3.0.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.3.0.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.3.0.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.3.0.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.3.0.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.3.0.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.3.0.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.3.0.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.3.1.beta\n",
      "✅ Weight unchanged: model.encoders.3.1.gamma\n",
      "❌ Weight changed: model.encoders.3.1.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.3.1.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.3.1.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.3.1.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.3.1.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.3.1.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.3.1.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.3.1.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.3.1.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.3.1.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.3.1.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.3.1.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.3.1.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.3.1.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.3.1.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.3.1.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.3.2.beta\n",
      "✅ Weight unchanged: model.encoders.3.2.gamma\n",
      "❌ Weight changed: model.encoders.3.2.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.3.2.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.3.2.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.3.2.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.3.2.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.3.2.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.3.2.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.3.2.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.3.2.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.3.2.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.3.2.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.3.2.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.3.2.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.3.2.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.3.2.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.3.2.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.3.3.beta\n",
      "✅ Weight unchanged: model.encoders.3.3.gamma\n",
      "❌ Weight changed: model.encoders.3.3.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.3.3.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.3.3.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.3.3.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.3.3.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.3.3.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.3.3.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.3.3.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.3.3.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.3.3.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.3.3.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.3.3.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.3.3.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.3.3.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.3.3.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.3.3.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.3.4.beta\n",
      "✅ Weight unchanged: model.encoders.3.4.gamma\n",
      "❌ Weight changed: model.encoders.3.4.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.3.4.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.3.4.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.3.4.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.3.4.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.3.4.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.3.4.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.3.4.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.3.4.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.3.4.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.3.4.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.3.4.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.3.4.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.3.4.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.3.4.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.3.4.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.3.5.beta\n",
      "✅ Weight unchanged: model.encoders.3.5.gamma\n",
      "❌ Weight changed: model.encoders.3.5.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.3.5.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.3.5.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.3.5.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.3.5.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.3.5.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.3.5.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.3.5.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.3.5.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.3.5.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.3.5.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.3.5.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.3.5.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.3.5.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.3.5.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.3.5.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.3.6.beta\n",
      "✅ Weight unchanged: model.encoders.3.6.gamma\n",
      "❌ Weight changed: model.encoders.3.6.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.3.6.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.3.6.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.3.6.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.3.6.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.3.6.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.3.6.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.3.6.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.3.6.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.3.6.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.3.6.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.3.6.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.3.6.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.3.6.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.3.6.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.3.6.norm2.bias\n",
      "✅ Weight unchanged: model.encoders.3.7.beta\n",
      "✅ Weight unchanged: model.encoders.3.7.gamma\n",
      "❌ Weight changed: model.encoders.3.7.mod_conv1.weight\n",
      "✅ Weight unchanged: model.encoders.3.7.mod_conv1.bias\n",
      "❌ Weight changed: model.encoders.3.7.mod_conv2.weight\n",
      "✅ Weight unchanged: model.encoders.3.7.mod_conv2.bias\n",
      "❌ Weight changed: model.encoders.3.7.mod_conv3.weight\n",
      "✅ Weight unchanged: model.encoders.3.7.mod_conv3.bias\n",
      "❌ Weight changed: model.encoders.3.7.sca_conv.weight\n",
      "✅ Weight unchanged: model.encoders.3.7.sca_conv.bias\n",
      "❌ Weight changed: model.encoders.3.7.mod_conv4.weight\n",
      "✅ Weight unchanged: model.encoders.3.7.mod_conv4.bias\n",
      "❌ Weight changed: model.encoders.3.7.mod_conv5.weight\n",
      "✅ Weight unchanged: model.encoders.3.7.mod_conv5.bias\n",
      "✅ Weight unchanged: model.encoders.3.7.norm1.weight\n",
      "✅ Weight unchanged: model.encoders.3.7.norm1.bias\n",
      "✅ Weight unchanged: model.encoders.3.7.norm2.weight\n",
      "✅ Weight unchanged: model.encoders.3.7.norm2.bias\n",
      "✅ Weight unchanged: model.decoders.0.0.beta\n",
      "✅ Weight unchanged: model.decoders.0.0.gamma\n",
      "❌ Weight changed: model.decoders.0.0.mod_conv1.weight\n",
      "✅ Weight unchanged: model.decoders.0.0.mod_conv1.bias\n",
      "❌ Weight changed: model.decoders.0.0.mod_conv2.weight\n",
      "✅ Weight unchanged: model.decoders.0.0.mod_conv2.bias\n",
      "❌ Weight changed: model.decoders.0.0.mod_conv3.weight\n",
      "✅ Weight unchanged: model.decoders.0.0.mod_conv3.bias\n",
      "❌ Weight changed: model.decoders.0.0.sca_conv.weight\n",
      "✅ Weight unchanged: model.decoders.0.0.sca_conv.bias\n",
      "❌ Weight changed: model.decoders.0.0.mod_conv4.weight\n",
      "✅ Weight unchanged: model.decoders.0.0.mod_conv4.bias\n",
      "❌ Weight changed: model.decoders.0.0.mod_conv5.weight\n",
      "✅ Weight unchanged: model.decoders.0.0.mod_conv5.bias\n",
      "✅ Weight unchanged: model.decoders.0.0.norm1.weight\n",
      "✅ Weight unchanged: model.decoders.0.0.norm1.bias\n",
      "✅ Weight unchanged: model.decoders.0.0.norm2.weight\n",
      "✅ Weight unchanged: model.decoders.0.0.norm2.bias\n",
      "✅ Weight unchanged: model.decoders.0.1.beta\n",
      "✅ Weight unchanged: model.decoders.0.1.gamma\n",
      "❌ Weight changed: model.decoders.0.1.mod_conv1.weight\n",
      "✅ Weight unchanged: model.decoders.0.1.mod_conv1.bias\n",
      "❌ Weight changed: model.decoders.0.1.mod_conv2.weight\n",
      "✅ Weight unchanged: model.decoders.0.1.mod_conv2.bias\n",
      "❌ Weight changed: model.decoders.0.1.mod_conv3.weight\n",
      "✅ Weight unchanged: model.decoders.0.1.mod_conv3.bias\n",
      "❌ Weight changed: model.decoders.0.1.sca_conv.weight\n",
      "✅ Weight unchanged: model.decoders.0.1.sca_conv.bias\n",
      "❌ Weight changed: model.decoders.0.1.mod_conv4.weight\n",
      "✅ Weight unchanged: model.decoders.0.1.mod_conv4.bias\n",
      "❌ Weight changed: model.decoders.0.1.mod_conv5.weight\n",
      "✅ Weight unchanged: model.decoders.0.1.mod_conv5.bias\n",
      "✅ Weight unchanged: model.decoders.0.1.norm1.weight\n",
      "✅ Weight unchanged: model.decoders.0.1.norm1.bias\n",
      "✅ Weight unchanged: model.decoders.0.1.norm2.weight\n",
      "✅ Weight unchanged: model.decoders.0.1.norm2.bias\n",
      "✅ Weight unchanged: model.decoders.1.0.beta\n",
      "✅ Weight unchanged: model.decoders.1.0.gamma\n",
      "❌ Weight changed: model.decoders.1.0.mod_conv1.weight\n",
      "✅ Weight unchanged: model.decoders.1.0.mod_conv1.bias\n",
      "❌ Weight changed: model.decoders.1.0.mod_conv2.weight\n",
      "✅ Weight unchanged: model.decoders.1.0.mod_conv2.bias\n",
      "❌ Weight changed: model.decoders.1.0.mod_conv3.weight\n",
      "✅ Weight unchanged: model.decoders.1.0.mod_conv3.bias\n",
      "❌ Weight changed: model.decoders.1.0.sca_conv.weight\n",
      "✅ Weight unchanged: model.decoders.1.0.sca_conv.bias\n",
      "❌ Weight changed: model.decoders.1.0.mod_conv4.weight\n",
      "✅ Weight unchanged: model.decoders.1.0.mod_conv4.bias\n",
      "❌ Weight changed: model.decoders.1.0.mod_conv5.weight\n",
      "✅ Weight unchanged: model.decoders.1.0.mod_conv5.bias\n",
      "✅ Weight unchanged: model.decoders.1.0.norm1.weight\n",
      "✅ Weight unchanged: model.decoders.1.0.norm1.bias\n",
      "✅ Weight unchanged: model.decoders.1.0.norm2.weight\n",
      "✅ Weight unchanged: model.decoders.1.0.norm2.bias\n",
      "✅ Weight unchanged: model.decoders.1.1.beta\n",
      "✅ Weight unchanged: model.decoders.1.1.gamma\n",
      "❌ Weight changed: model.decoders.1.1.mod_conv1.weight\n",
      "✅ Weight unchanged: model.decoders.1.1.mod_conv1.bias\n",
      "❌ Weight changed: model.decoders.1.1.mod_conv2.weight\n",
      "✅ Weight unchanged: model.decoders.1.1.mod_conv2.bias\n",
      "❌ Weight changed: model.decoders.1.1.mod_conv3.weight\n",
      "✅ Weight unchanged: model.decoders.1.1.mod_conv3.bias\n",
      "❌ Weight changed: model.decoders.1.1.sca_conv.weight\n",
      "✅ Weight unchanged: model.decoders.1.1.sca_conv.bias\n",
      "❌ Weight changed: model.decoders.1.1.mod_conv4.weight\n",
      "✅ Weight unchanged: model.decoders.1.1.mod_conv4.bias\n",
      "❌ Weight changed: model.decoders.1.1.mod_conv5.weight\n",
      "✅ Weight unchanged: model.decoders.1.1.mod_conv5.bias\n",
      "✅ Weight unchanged: model.decoders.1.1.norm1.weight\n",
      "✅ Weight unchanged: model.decoders.1.1.norm1.bias\n",
      "✅ Weight unchanged: model.decoders.1.1.norm2.weight\n",
      "✅ Weight unchanged: model.decoders.1.1.norm2.bias\n",
      "✅ Weight unchanged: model.decoders.2.0.beta\n",
      "✅ Weight unchanged: model.decoders.2.0.gamma\n",
      "❌ Weight changed: model.decoders.2.0.mod_conv1.weight\n",
      "✅ Weight unchanged: model.decoders.2.0.mod_conv1.bias\n",
      "❌ Weight changed: model.decoders.2.0.mod_conv2.weight\n",
      "✅ Weight unchanged: model.decoders.2.0.mod_conv2.bias\n",
      "❌ Weight changed: model.decoders.2.0.mod_conv3.weight\n",
      "✅ Weight unchanged: model.decoders.2.0.mod_conv3.bias\n",
      "❌ Weight changed: model.decoders.2.0.sca_conv.weight\n",
      "✅ Weight unchanged: model.decoders.2.0.sca_conv.bias\n",
      "❌ Weight changed: model.decoders.2.0.mod_conv4.weight\n",
      "✅ Weight unchanged: model.decoders.2.0.mod_conv4.bias\n",
      "❌ Weight changed: model.decoders.2.0.mod_conv5.weight\n",
      "✅ Weight unchanged: model.decoders.2.0.mod_conv5.bias\n",
      "✅ Weight unchanged: model.decoders.2.0.norm1.weight\n",
      "✅ Weight unchanged: model.decoders.2.0.norm1.bias\n",
      "✅ Weight unchanged: model.decoders.2.0.norm2.weight\n",
      "✅ Weight unchanged: model.decoders.2.0.norm2.bias\n",
      "✅ Weight unchanged: model.decoders.2.1.beta\n",
      "✅ Weight unchanged: model.decoders.2.1.gamma\n",
      "❌ Weight changed: model.decoders.2.1.mod_conv1.weight\n",
      "✅ Weight unchanged: model.decoders.2.1.mod_conv1.bias\n",
      "❌ Weight changed: model.decoders.2.1.mod_conv2.weight\n",
      "✅ Weight unchanged: model.decoders.2.1.mod_conv2.bias\n",
      "❌ Weight changed: model.decoders.2.1.mod_conv3.weight\n",
      "✅ Weight unchanged: model.decoders.2.1.mod_conv3.bias\n",
      "❌ Weight changed: model.decoders.2.1.sca_conv.weight\n",
      "✅ Weight unchanged: model.decoders.2.1.sca_conv.bias\n",
      "❌ Weight changed: model.decoders.2.1.mod_conv4.weight\n",
      "✅ Weight unchanged: model.decoders.2.1.mod_conv4.bias\n",
      "❌ Weight changed: model.decoders.2.1.mod_conv5.weight\n",
      "✅ Weight unchanged: model.decoders.2.1.mod_conv5.bias\n",
      "✅ Weight unchanged: model.decoders.2.1.norm1.weight\n",
      "✅ Weight unchanged: model.decoders.2.1.norm1.bias\n",
      "✅ Weight unchanged: model.decoders.2.1.norm2.weight\n",
      "✅ Weight unchanged: model.decoders.2.1.norm2.bias\n",
      "✅ Weight unchanged: model.decoders.3.0.beta\n",
      "✅ Weight unchanged: model.decoders.3.0.gamma\n",
      "❌ Weight changed: model.decoders.3.0.mod_conv1.weight\n",
      "✅ Weight unchanged: model.decoders.3.0.mod_conv1.bias\n",
      "❌ Weight changed: model.decoders.3.0.mod_conv2.weight\n",
      "✅ Weight unchanged: model.decoders.3.0.mod_conv2.bias\n",
      "❌ Weight changed: model.decoders.3.0.mod_conv3.weight\n",
      "✅ Weight unchanged: model.decoders.3.0.mod_conv3.bias\n",
      "❌ Weight changed: model.decoders.3.0.sca_conv.weight\n",
      "✅ Weight unchanged: model.decoders.3.0.sca_conv.bias\n",
      "❌ Weight changed: model.decoders.3.0.mod_conv4.weight\n",
      "✅ Weight unchanged: model.decoders.3.0.mod_conv4.bias\n",
      "❌ Weight changed: model.decoders.3.0.mod_conv5.weight\n",
      "✅ Weight unchanged: model.decoders.3.0.mod_conv5.bias\n",
      "✅ Weight unchanged: model.decoders.3.0.norm1.weight\n",
      "✅ Weight unchanged: model.decoders.3.0.norm1.bias\n",
      "✅ Weight unchanged: model.decoders.3.0.norm2.weight\n",
      "✅ Weight unchanged: model.decoders.3.0.norm2.bias\n",
      "✅ Weight unchanged: model.decoders.3.1.beta\n",
      "✅ Weight unchanged: model.decoders.3.1.gamma\n",
      "❌ Weight changed: model.decoders.3.1.mod_conv1.weight\n",
      "✅ Weight unchanged: model.decoders.3.1.mod_conv1.bias\n",
      "❌ Weight changed: model.decoders.3.1.mod_conv2.weight\n",
      "✅ Weight unchanged: model.decoders.3.1.mod_conv2.bias\n",
      "❌ Weight changed: model.decoders.3.1.mod_conv3.weight\n",
      "✅ Weight unchanged: model.decoders.3.1.mod_conv3.bias\n",
      "❌ Weight changed: model.decoders.3.1.sca_conv.weight\n",
      "✅ Weight unchanged: model.decoders.3.1.sca_conv.bias\n",
      "❌ Weight changed: model.decoders.3.1.mod_conv4.weight\n",
      "✅ Weight unchanged: model.decoders.3.1.mod_conv4.bias\n",
      "❌ Weight changed: model.decoders.3.1.mod_conv5.weight\n",
      "✅ Weight unchanged: model.decoders.3.1.mod_conv5.bias\n",
      "✅ Weight unchanged: model.decoders.3.1.norm1.weight\n",
      "✅ Weight unchanged: model.decoders.3.1.norm1.bias\n",
      "✅ Weight unchanged: model.decoders.3.1.norm2.weight\n",
      "✅ Weight unchanged: model.decoders.3.1.norm2.bias\n",
      "✅ Weight unchanged: model.downs.0.weight\n",
      "✅ Weight unchanged: model.downs.0.bias\n",
      "✅ Weight unchanged: model.downs.1.weight\n",
      "✅ Weight unchanged: model.downs.1.bias\n",
      "✅ Weight unchanged: model.downs.2.weight\n",
      "✅ Weight unchanged: model.downs.2.bias\n",
      "✅ Weight unchanged: model.downs.3.weight\n",
      "✅ Weight unchanged: model.downs.3.bias\n",
      "❌ Weight changed: model.ups_convs.0.weight\n",
      "❌ Weight changed: model.ups_convs.1.weight\n",
      "❌ Weight changed: model.ups_convs.2.weight\n",
      "❌ Weight changed: model.ups_convs.3.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.beta\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.gamma\n",
      "❌ Weight changed: model.middle_blks_seq.0.mod_conv1.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.mod_conv1.bias\n",
      "❌ Weight changed: model.middle_blks_seq.0.mod_conv2.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.mod_conv2.bias\n",
      "❌ Weight changed: model.middle_blks_seq.0.mod_conv3.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.mod_conv3.bias\n",
      "❌ Weight changed: model.middle_blks_seq.0.sca_conv.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.sca_conv.bias\n",
      "❌ Weight changed: model.middle_blks_seq.0.mod_conv4.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.mod_conv4.bias\n",
      "❌ Weight changed: model.middle_blks_seq.0.mod_conv5.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.mod_conv5.bias\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.norm1.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.norm1.bias\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.norm2.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.0.norm2.bias\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.beta\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.gamma\n",
      "❌ Weight changed: model.middle_blks_seq.1.mod_conv1.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.mod_conv1.bias\n",
      "❌ Weight changed: model.middle_blks_seq.1.mod_conv2.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.mod_conv2.bias\n",
      "❌ Weight changed: model.middle_blks_seq.1.mod_conv3.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.mod_conv3.bias\n",
      "❌ Weight changed: model.middle_blks_seq.1.sca_conv.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.sca_conv.bias\n",
      "❌ Weight changed: model.middle_blks_seq.1.mod_conv4.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.mod_conv4.bias\n",
      "❌ Weight changed: model.middle_blks_seq.1.mod_conv5.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.mod_conv5.bias\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.norm1.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.norm1.bias\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.norm2.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.1.norm2.bias\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.beta\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.gamma\n",
      "❌ Weight changed: model.middle_blks_seq.2.mod_conv1.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.mod_conv1.bias\n",
      "❌ Weight changed: model.middle_blks_seq.2.mod_conv2.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.mod_conv2.bias\n",
      "❌ Weight changed: model.middle_blks_seq.2.mod_conv3.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.mod_conv3.bias\n",
      "❌ Weight changed: model.middle_blks_seq.2.sca_conv.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.sca_conv.bias\n",
      "❌ Weight changed: model.middle_blks_seq.2.mod_conv4.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.mod_conv4.bias\n",
      "❌ Weight changed: model.middle_blks_seq.2.mod_conv5.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.mod_conv5.bias\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.norm1.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.norm1.bias\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.norm2.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.2.norm2.bias\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.beta\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.gamma\n",
      "❌ Weight changed: model.middle_blks_seq.3.mod_conv1.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.mod_conv1.bias\n",
      "❌ Weight changed: model.middle_blks_seq.3.mod_conv2.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.mod_conv2.bias\n",
      "❌ Weight changed: model.middle_blks_seq.3.mod_conv3.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.mod_conv3.bias\n",
      "❌ Weight changed: model.middle_blks_seq.3.sca_conv.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.sca_conv.bias\n",
      "❌ Weight changed: model.middle_blks_seq.3.mod_conv4.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.mod_conv4.bias\n",
      "❌ Weight changed: model.middle_blks_seq.3.mod_conv5.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.mod_conv5.bias\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.norm1.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.norm1.bias\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.norm2.weight\n",
      "✅ Weight unchanged: model.middle_blks_seq.3.norm2.bias\n",
      "✅ Weight unchanged: model.ending.weight\n",
      "✅ Weight unchanged: model.ending.bias\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for (name, param_pre) in pre_model.named_parameters():\n",
    "    param_post = dict(model.named_parameters())[name]\n",
    "    \n",
    "    # Skip style parameters (they are allowed to change)\n",
    "    if 'style_weight' in name or 'style_bias' in name:\n",
    "        continue\n",
    "\n",
    "    if not torch.allclose(param_pre, param_post, atol=1e-6):\n",
    "        print(f\"❌ Weight changed: {name}\")\n",
    "    else:\n",
    "        print(f\"✅ Weight unchanged: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "batch[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Forward pass completed successfully.\n",
      "Output shape: torch.Size([2, 3, 64, 64, 64])\n",
      "✅ Backward pass completed successfully.\n",
      "\n",
      "🔍 Parameter gradient check:\n",
      "✔️  'model.encoders.0.0.conv.style_weight': grad norm = 0.0027\n",
      "✔️  'model.encoders.0.0.conv.style_bias': grad norm = 0.0018\n",
      "✔️  'model.encoders.0.0.conv.weight': grad norm = 0.0378\n",
      "✔️  'model.encoders.0.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.0.0.bn.weight': grad norm = 0.0034\n",
      "✔️  'model.encoders.0.0.bn.bias': grad norm = 0.0018\n",
      "✔️  'model.encoders.1.0.conv.style_weight': grad norm = 0.0042\n",
      "✔️  'model.encoders.1.0.conv.style_bias': grad norm = 0.0016\n",
      "✔️  'model.encoders.1.0.conv.weight': grad norm = 0.0510\n",
      "✔️  'model.encoders.1.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.1.0.bn.weight': grad norm = 0.0017\n",
      "✔️  'model.encoders.1.0.bn.bias': grad norm = 0.0015\n",
      "✔️  'model.encoders.1.1.conv.style_weight': grad norm = 0.0055\n",
      "✔️  'model.encoders.1.1.conv.style_bias': grad norm = 0.0029\n",
      "✔️  'model.encoders.1.1.conv.weight': grad norm = 0.0347\n",
      "✔️  'model.encoders.1.1.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.1.1.bn.weight': grad norm = 0.0048\n",
      "✔️  'model.encoders.1.1.bn.bias': grad norm = 0.0032\n",
      "✔️  'model.encoders.2.0.conv.style_weight': grad norm = 0.0013\n",
      "✔️  'model.encoders.2.0.conv.style_bias': grad norm = 0.0007\n",
      "✔️  'model.encoders.2.0.conv.weight': grad norm = 0.0174\n",
      "✔️  'model.encoders.2.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.2.0.bn.weight': grad norm = 0.0005\n",
      "✔️  'model.encoders.2.0.bn.bias': grad norm = 0.0005\n",
      "✔️  'model.encoders.3.0.conv.style_weight': grad norm = 0.0008\n",
      "✔️  'model.encoders.3.0.conv.style_bias': grad norm = 0.0005\n",
      "✔️  'model.encoders.3.0.conv.weight': grad norm = 0.0208\n",
      "✔️  'model.encoders.3.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.3.0.bn.weight': grad norm = 0.0007\n",
      "✔️  'model.encoders.3.0.bn.bias': grad norm = 0.0003\n",
      "✔️  'model.encoders.3.1.conv.style_weight': grad norm = 0.0012\n",
      "✔️  'model.encoders.3.1.conv.style_bias': grad norm = 0.0006\n",
      "✔️  'model.encoders.3.1.conv.weight': grad norm = 0.0183\n",
      "✔️  'model.encoders.3.1.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.3.1.bn.weight': grad norm = 0.0005\n",
      "✔️  'model.encoders.3.1.bn.bias': grad norm = 0.0004\n",
      "✔️  'model.encoders.4.0.conv.style_weight': grad norm = 0.0005\n",
      "✔️  'model.encoders.4.0.conv.style_bias': grad norm = 0.0002\n",
      "✔️  'model.encoders.4.0.conv.weight': grad norm = 0.0108\n",
      "✔️  'model.encoders.4.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.4.0.bn.weight': grad norm = 0.0003\n",
      "✔️  'model.encoders.4.0.bn.bias': grad norm = 0.0002\n",
      "✔️  'model.encoders.5.0.conv.style_weight': grad norm = 0.0004\n",
      "✔️  'model.encoders.5.0.conv.style_bias': grad norm = 0.0002\n",
      "✔️  'model.encoders.5.0.conv.weight': grad norm = 0.0129\n",
      "✔️  'model.encoders.5.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.5.0.bn.weight': grad norm = 0.0002\n",
      "✔️  'model.encoders.5.0.bn.bias': grad norm = 0.0001\n",
      "✔️  'model.encoders.5.1.conv.style_weight': grad norm = 0.0003\n",
      "✔️  'model.encoders.5.1.conv.style_bias': grad norm = 0.0002\n",
      "✔️  'model.encoders.5.1.conv.weight': grad norm = 0.0110\n",
      "✔️  'model.encoders.5.1.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.5.1.bn.weight': grad norm = 0.0002\n",
      "✔️  'model.encoders.5.1.bn.bias': grad norm = 0.0002\n",
      "✔️  'model.encoders.6.0.conv.style_weight': grad norm = 0.0001\n",
      "✔️  'model.encoders.6.0.conv.style_bias': grad norm = 0.0001\n",
      "✔️  'model.encoders.6.0.conv.weight': grad norm = 0.0044\n",
      "✔️  'model.encoders.6.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.6.0.bn.weight': grad norm = 0.0001\n",
      "✔️  'model.encoders.6.0.bn.bias': grad norm = 0.0001\n",
      "✔️  'model.encoders.7.0.conv.style_weight': grad norm = 0.0001\n",
      "✔️  'model.encoders.7.0.conv.style_bias': grad norm = 0.0001\n",
      "✔️  'model.encoders.7.0.conv.weight': grad norm = 0.0054\n",
      "✔️  'model.encoders.7.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.7.0.bn.weight': grad norm = 0.0001\n",
      "✔️  'model.encoders.7.0.bn.bias': grad norm = 0.0001\n",
      "✔️  'model.encoders.7.1.conv.style_weight': grad norm = 0.0001\n",
      "✔️  'model.encoders.7.1.conv.style_bias': grad norm = 0.0001\n",
      "✔️  'model.encoders.7.1.conv.weight': grad norm = 0.0043\n",
      "✔️  'model.encoders.7.1.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.encoders.7.1.bn.weight': grad norm = 0.0001\n",
      "✔️  'model.encoders.7.1.bn.bias': grad norm = 0.0001\n",
      "✔️  'model.decoders.0.style_weight': grad norm = 0.0001\n",
      "✔️  'model.decoders.0.style_bias': grad norm = 0.0001\n",
      "✔️  'model.decoders.0.weight': grad norm = 0.0031\n",
      "✔️  'model.decoders.0.bias': grad norm = 0.0001\n",
      "✔️  'model.decoders.1.0.conv.style_weight': grad norm = 0.0003\n",
      "✔️  'model.decoders.1.0.conv.style_bias': grad norm = 0.0001\n",
      "✔️  'model.decoders.1.0.conv.weight': grad norm = 0.0119\n",
      "✔️  'model.decoders.1.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.decoders.1.0.bn.weight': grad norm = 0.0002\n",
      "✔️  'model.decoders.1.0.bn.bias': grad norm = 0.0001\n",
      "✔️  'model.decoders.1.1.conv.style_weight': grad norm = 0.0003\n",
      "✔️  'model.decoders.1.1.conv.style_bias': grad norm = 0.0001\n",
      "✔️  'model.decoders.1.1.conv.weight': grad norm = 0.0074\n",
      "✔️  'model.decoders.1.1.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.decoders.1.1.bn.weight': grad norm = 0.0001\n",
      "✔️  'model.decoders.1.1.bn.bias': grad norm = 0.0001\n",
      "✔️  'model.decoders.2.style_weight': grad norm = 0.0003\n",
      "✔️  'model.decoders.2.style_bias': grad norm = 0.0001\n",
      "✔️  'model.decoders.2.weight': grad norm = 0.0051\n",
      "✔️  'model.decoders.2.bias': grad norm = 0.0005\n",
      "✔️  'model.decoders.3.0.conv.style_weight': grad norm = 0.0010\n",
      "✔️  'model.decoders.3.0.conv.style_bias': grad norm = 0.0003\n",
      "✔️  'model.decoders.3.0.conv.weight': grad norm = 0.0200\n",
      "✔️  'model.decoders.3.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.decoders.3.0.bn.weight': grad norm = 0.0004\n",
      "✔️  'model.decoders.3.0.bn.bias': grad norm = 0.0003\n",
      "✔️  'model.decoders.3.1.conv.style_weight': grad norm = 0.0006\n",
      "✔️  'model.decoders.3.1.conv.style_bias': grad norm = 0.0002\n",
      "✔️  'model.decoders.3.1.conv.weight': grad norm = 0.0112\n",
      "✔️  'model.decoders.3.1.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.decoders.3.1.bn.weight': grad norm = 0.0004\n",
      "✔️  'model.decoders.3.1.bn.bias': grad norm = 0.0003\n",
      "✔️  'model.decoders.4.style_weight': grad norm = 0.0006\n",
      "✔️  'model.decoders.4.style_bias': grad norm = 0.0002\n",
      "✔️  'model.decoders.4.weight': grad norm = 0.0088\n",
      "✔️  'model.decoders.4.bias': grad norm = 0.0013\n",
      "✔️  'model.decoders.5.0.conv.style_weight': grad norm = 0.0060\n",
      "✔️  'model.decoders.5.0.conv.style_bias': grad norm = 0.0016\n",
      "✔️  'model.decoders.5.0.conv.weight': grad norm = 0.0763\n",
      "✔️  'model.decoders.5.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.decoders.5.0.bn.weight': grad norm = 0.0010\n",
      "✔️  'model.decoders.5.0.bn.bias': grad norm = 0.0010\n",
      "✔️  'model.decoders.5.1.conv.style_weight': grad norm = 0.0030\n",
      "✔️  'model.decoders.5.1.conv.style_bias': grad norm = 0.0010\n",
      "✔️  'model.decoders.5.1.conv.weight': grad norm = 0.0273\n",
      "✔️  'model.decoders.5.1.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.decoders.5.1.bn.weight': grad norm = 0.0051\n",
      "✔️  'model.decoders.5.1.bn.bias': grad norm = 0.0055\n",
      "✔️  'model.decoders.6.style_weight': grad norm = 0.0057\n",
      "✔️  'model.decoders.6.style_bias': grad norm = 0.0040\n",
      "✔️  'model.decoders.6.weight': grad norm = 0.0598\n",
      "✔️  'model.decoders.6.bias': grad norm = 0.0080\n",
      "✔️  'model.decoders.7.0.conv.style_weight': grad norm = 0.0757\n",
      "✔️  'model.decoders.7.0.conv.style_bias': grad norm = 0.0101\n",
      "✔️  'model.decoders.7.0.conv.weight': grad norm = 0.3070\n",
      "✔️  'model.decoders.7.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.decoders.7.0.bn.weight': grad norm = 0.0226\n",
      "✔️  'model.decoders.7.0.bn.bias': grad norm = 0.0158\n",
      "✔️  'model.decoders.7.1.conv.style_weight': grad norm = 0.0463\n",
      "✔️  'model.decoders.7.1.conv.style_bias': grad norm = 0.0172\n",
      "✔️  'model.decoders.7.1.conv.weight': grad norm = 0.6155\n",
      "✔️  'model.decoders.7.1.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.decoders.7.1.bn.weight': grad norm = 0.5495\n",
      "✔️  'model.decoders.7.1.bn.bias': grad norm = 0.4304\n",
      "✔️  'model.init_conv.0.conv.style_weight': grad norm = 0.0083\n",
      "✔️  'model.init_conv.0.conv.style_bias': grad norm = 0.0026\n",
      "✔️  'model.init_conv.0.conv.weight': grad norm = 0.0809\n",
      "✔️  'model.init_conv.0.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.init_conv.0.bn.weight': grad norm = 0.0484\n",
      "✔️  'model.init_conv.0.bn.bias': grad norm = 0.0357\n",
      "✔️  'model.init_conv.1.conv.style_weight': grad norm = 0.0692\n",
      "✔️  'model.init_conv.1.conv.style_bias': grad norm = 0.0133\n",
      "✔️  'model.init_conv.1.conv.weight': grad norm = 0.2242\n",
      "✔️  'model.init_conv.1.conv.bias': grad norm = 0.0000\n",
      "✔️  'model.init_conv.1.bn.weight': grad norm = 0.0148\n",
      "✔️  'model.init_conv.1.bn.bias': grad norm = 0.0115\n",
      "✔️  'model.final_conv.style_weight': grad norm = 0.1844\n",
      "✔️  'model.final_conv.style_bias': grad norm = 0.1343\n",
      "✔️  'model.final_conv.weight': grad norm = 0.4820\n",
      "✔️  'model.final_conv.bias': grad norm = 0.3748\n",
      "\n",
      "🧩 Inactive modules (not used in forward pass):\n",
      "⚠️  MSELoss at MSELoss()\n",
      "⚠️  PeakSignalNoiseRatio at PeakSignalNoiseRatio()\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_shape = (2, 3, 64, 64, 64)  \n",
    "output_shape = (2, 3, 64, 64, 64) \n",
    "style_shape = (2, 5) \n",
    "verify_model(model, input_shape, output_shape, style_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def verify_model(model, input_shape, output_shape=None, style_shape=None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Verify that a model can successfully complete forward and backward passes,\n",
    "    and detect inactive modules and parameters.\n",
    "    \n",
    "    Args:\n",
    "        model: The PyTorch model to verify\n",
    "        input_shape: Shape of input tensor (including batch size)\n",
    "        output_shape: Expected output shape (for loss calculation)\n",
    "        style_shape: Shape of the style tensor if required\n",
    "        device: Device to run verification on\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Track modules that were activated in the forward pass\n",
    "    visited_modules = set()\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        visited_modules.add(module)\n",
    "\n",
    "    # Register hooks on all submodules\n",
    "    hooks = []\n",
    "    for module in model.modules():\n",
    "        if not isinstance(module, nn.Sequential) and module != model:\n",
    "            hooks.append(module.register_forward_hook(forward_hook))\n",
    "\n",
    "    try:\n",
    "        # Create dummy input\n",
    "        dummy_input = torch.randn(*input_shape).to(device)\n",
    "        dummy_input.requires_grad = True\n",
    "\n",
    "        if style_shape is not None:\n",
    "            dummy_style = torch.randn(*style_shape).to(device)\n",
    "            output = model(dummy_input, dummy_style)\n",
    "        else:\n",
    "            output = model(dummy_input)\n",
    "\n",
    "        print(\"✅ Forward pass completed successfully.\")\n",
    "        print(f\"Output shape: {output.shape if not isinstance(output, (list, tuple)) else [o.shape for o in output]}\")\n",
    "\n",
    "        # Dummy target\n",
    "        if output_shape is not None:\n",
    "            if isinstance(output, (list, tuple, dict)):\n",
    "                dummy_target = [torch.randn(*shape).to(device) for shape in output_shape]\n",
    "                loss = sum(torch.nn.functional.mse_loss(o, t) for o, t in zip(output, dummy_target))\n",
    "            else:\n",
    "                dummy_target = torch.randn(*output_shape).to(device)\n",
    "                loss = torch.nn.functional.mse_loss(output, dummy_target)\n",
    "        else:\n",
    "            loss = output.sum() if not isinstance(output, (list, tuple)) else sum(o.sum() for o in output)\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        print(\"✅ Backward pass completed successfully.\")\n",
    "\n",
    "        # Report gradients\n",
    "        print(\"\\n🔍 Parameter gradient check:\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if param.grad is None:\n",
    "                    print(f\"⚠️  Parameter '{name}' has no gradient!\")\n",
    "                else:\n",
    "                    print(f\"✔️  '{name}': grad norm = {param.grad.norm().item():.4f}\")\n",
    "            else:\n",
    "                print(f\"ℹ️  '{name}' does not require grad.\")\n",
    "\n",
    "        # Report unused modules\n",
    "        print(\"\\n🧩 Inactive modules (not used in forward pass):\")\n",
    "        for module in model.modules():\n",
    "            # Ignore root model and container modules (Sequential, ModuleList)\n",
    "            if module not in visited_modules and module != model and \\\n",
    "            not isinstance(module, (nn.Sequential, nn.ModuleList, nn.ModuleDict)):\n",
    "                print(f\"⚠️  {module.__class__.__name__} at {module}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during verification: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Forward pass completed successfully.\n",
      "Output shape: torch.Size([2, 3, 64, 64, 64])\n",
      "✅ Backward pass completed successfully.\n",
      "\n",
      "🔍 Parameter gradient check:\n",
      "✔️  'intro.weight': grad norm = 0.6802\n",
      "✔️  'intro.bias': grad norm = 0.0202\n",
      "✔️  'encoders.0.0.beta': grad norm = 0.0024\n",
      "✔️  'encoders.0.0.gamma': grad norm = 0.0136\n",
      "✔️  'encoders.0.0.conv1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.conv1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.conv2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.conv2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.conv3.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.conv3.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.conv4.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.conv4.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.conv5.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.conv5.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.norm1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.norm1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.norm2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.0.norm2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.beta': grad norm = 0.0026\n",
      "✔️  'encoders.0.1.gamma': grad norm = 0.0098\n",
      "✔️  'encoders.0.1.conv1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.conv1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.conv2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.conv2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.conv3.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.conv3.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.conv4.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.conv4.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.conv5.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.conv5.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.norm1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.norm1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.norm2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.0.1.norm2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.beta': grad norm = 0.0003\n",
      "✔️  'encoders.1.0.gamma': grad norm = 0.0018\n",
      "✔️  'encoders.1.0.conv1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.conv1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.conv2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.conv2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.conv3.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.conv3.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.conv4.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.conv4.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.conv5.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.conv5.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.norm1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.norm1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.norm2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.0.norm2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.beta': grad norm = 0.0002\n",
      "✔️  'encoders.1.1.gamma': grad norm = 0.0022\n",
      "✔️  'encoders.1.1.conv1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.conv1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.conv2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.conv2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.conv3.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.conv3.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.conv4.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.conv4.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.conv5.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.conv5.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.norm1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.norm1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.norm2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.1.1.norm2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.beta': grad norm = 0.0001\n",
      "✔️  'encoders.2.0.gamma': grad norm = 0.0003\n",
      "✔️  'encoders.2.0.conv1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.conv1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.conv2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.conv2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.conv3.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.conv3.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.conv4.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.conv4.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.conv5.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.conv5.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.norm1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.norm1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.norm2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.0.norm2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.beta': grad norm = 0.0001\n",
      "✔️  'encoders.2.1.gamma': grad norm = 0.0002\n",
      "✔️  'encoders.2.1.conv1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.conv1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.conv2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.conv2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.conv3.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.conv3.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.conv4.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.conv4.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.conv5.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.conv5.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.norm1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.norm1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.norm2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.2.1.norm2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.beta': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.gamma': grad norm = 0.0001\n",
      "✔️  'encoders.3.0.conv1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.conv1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.conv2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.conv2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.conv3.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.conv3.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.conv4.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.conv4.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.conv5.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.conv5.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.norm1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.norm1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.norm2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.0.norm2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.beta': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.gamma': grad norm = 0.0001\n",
      "✔️  'encoders.3.1.conv1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.conv1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.conv2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.conv2.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.conv3.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.conv3.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.conv4.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.conv4.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.conv5.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.conv5.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.norm1.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.norm1.bias': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.norm2.weight': grad norm = 0.0000\n",
      "✔️  'encoders.3.1.norm2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.beta': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.gamma': grad norm = 0.0001\n",
      "✔️  'decoders.0.0.conv1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.conv1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.conv2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.conv2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.conv3.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.conv3.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.conv4.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.conv4.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.conv5.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.conv5.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.norm1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.norm1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.norm2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.0.norm2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.beta': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.gamma': grad norm = 0.0001\n",
      "✔️  'decoders.0.1.conv1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.conv1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.conv2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.conv2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.conv3.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.conv3.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.conv4.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.conv4.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.conv5.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.conv5.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.norm1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.norm1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.norm2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.0.1.norm2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.beta': grad norm = 0.0001\n",
      "✔️  'decoders.1.0.gamma': grad norm = 0.0003\n",
      "✔️  'decoders.1.0.conv1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.conv1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.conv2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.conv2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.conv3.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.conv3.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.conv4.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.conv4.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.conv5.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.conv5.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.norm1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.norm1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.norm2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.0.norm2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.beta': grad norm = 0.0001\n",
      "✔️  'decoders.1.1.gamma': grad norm = 0.0003\n",
      "✔️  'decoders.1.1.conv1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.conv1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.conv2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.conv2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.conv3.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.conv3.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.conv4.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.conv4.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.conv5.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.conv5.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.norm1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.norm1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.norm2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.1.1.norm2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.beta': grad norm = 0.0003\n",
      "✔️  'decoders.2.0.gamma': grad norm = 0.0018\n",
      "✔️  'decoders.2.0.conv1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.conv1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.conv2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.conv2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.conv3.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.conv3.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.conv4.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.conv4.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.conv5.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.conv5.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.norm1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.norm1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.norm2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.0.norm2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.beta': grad norm = 0.0003\n",
      "✔️  'decoders.2.1.gamma': grad norm = 0.0014\n",
      "✔️  'decoders.2.1.conv1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.conv1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.conv2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.conv2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.conv3.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.conv3.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.conv4.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.conv4.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.conv5.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.conv5.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.norm1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.norm1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.norm2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.2.1.norm2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.beta': grad norm = 0.0029\n",
      "✔️  'decoders.3.0.gamma': grad norm = 0.0093\n",
      "✔️  'decoders.3.0.conv1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.conv1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.conv2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.conv2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.conv3.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.conv3.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.conv4.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.conv4.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.conv5.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.conv5.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.norm1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.norm1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.norm2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.0.norm2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.beta': grad norm = 0.0024\n",
      "✔️  'decoders.3.1.gamma': grad norm = 0.0116\n",
      "✔️  'decoders.3.1.conv1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.conv1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.conv2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.conv2.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.conv3.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.conv3.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.conv4.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.conv4.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.conv5.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.conv5.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.norm1.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.norm1.bias': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.norm2.weight': grad norm = 0.0000\n",
      "✔️  'decoders.3.1.norm2.bias': grad norm = 0.0000\n",
      "✔️  'downs.0.weight': grad norm = 0.0778\n",
      "✔️  'downs.0.bias': grad norm = 0.0041\n",
      "✔️  'downs.1.weight': grad norm = 0.0085\n",
      "✔️  'downs.1.bias': grad norm = 0.0012\n",
      "✔️  'downs.2.weight': grad norm = 0.0014\n",
      "✔️  'downs.2.bias': grad norm = 0.0004\n",
      "✔️  'downs.3.weight': grad norm = 0.0006\n",
      "✔️  'downs.3.bias': grad norm = 0.0002\n",
      "✔️  'ups_convs.0.weight': grad norm = 0.0003\n",
      "✔️  'ups_convs.1.weight': grad norm = 0.0007\n",
      "✔️  'ups_convs.2.weight': grad norm = 0.0043\n",
      "✔️  'ups_convs.3.weight': grad norm = 0.0415\n",
      "✔️  'middle_blks_seq.0.beta': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.gamma': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.conv1.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.conv1.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.conv2.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.conv2.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.conv3.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.conv3.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.conv4.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.conv4.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.conv5.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.conv5.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.norm1.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.norm1.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.norm2.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.0.norm2.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.beta': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.gamma': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.conv1.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.conv1.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.conv2.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.conv2.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.conv3.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.conv3.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.sca.1.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.sca.1.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.conv4.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.conv4.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.conv5.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.conv5.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.norm1.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.norm1.bias': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.norm2.weight': grad norm = 0.0000\n",
      "✔️  'middle_blks_seq.1.norm2.bias': grad norm = 0.0000\n",
      "✔️  'ending.weight': grad norm = 1.5425\n",
      "✔️  'ending.bias': grad norm = 0.0304\n",
      "\n",
      "🧩 Inactive modules (not used in forward pass):\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from naf_net import NAFNet3D_modulated, BaselineBlock_SCA_FullyModulated, BaselineBlock_SCA_Modulated, BaselineBlock_SCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def verify_model(model, input_shape, output_shape=None, style_shape=None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Verify that a model can successfully complete forward and backward passes,\n",
    "    and detect inactive modules and parameters.\n",
    "    \n",
    "    Args:\n",
    "        model: The PyTorch model to verify\n",
    "        input_shape: Shape of input tensor (including batch size)\n",
    "        output_shape: Expected output shape (for loss calculation)\n",
    "        style_shape: Shape of the style tensor if required\n",
    "        device: Device to run verification on\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Track modules that were activated in the forward pass\n",
    "    visited_modules = set()\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        visited_modules.add(module)\n",
    "\n",
    "    # Register hooks on all submodules\n",
    "    hooks = []\n",
    "    for module in model.modules():\n",
    "        if not isinstance(module, nn.Sequential) and module != model:\n",
    "            hooks.append(module.register_forward_hook(forward_hook))\n",
    "\n",
    "    try:\n",
    "        # Create dummy input\n",
    "        dummy_input = torch.randn(*input_shape).to(device)\n",
    "        dummy_input.requires_grad = True\n",
    "\n",
    "        if style_shape is not None:\n",
    "            dummy_style = torch.randn(*style_shape).to(device)\n",
    "            output = model(dummy_input, dummy_style)\n",
    "        else:\n",
    "            output = model(dummy_input)\n",
    "\n",
    "        print(\"✅ Forward pass completed successfully.\")\n",
    "        print(f\"Output shape: {output.shape if not isinstance(output, (list, tuple)) else [o.shape for o in output]}\")\n",
    "\n",
    "        # Dummy target\n",
    "        if output_shape is not None:\n",
    "            if isinstance(output, (list, tuple, dict)):\n",
    "                dummy_target = [torch.randn(*shape).to(device) for shape in output_shape]\n",
    "                loss = sum(torch.nn.functional.mse_loss(o, t) for o, t in zip(output, dummy_target))\n",
    "            else:\n",
    "                dummy_target = torch.randn(*output_shape).to(device)\n",
    "                loss = torch.nn.functional.mse_loss(output, dummy_target)\n",
    "        else:\n",
    "            loss = output.sum() if not isinstance(output, (list, tuple)) else sum(o.sum() for o in output)\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        print(\"✅ Backward pass completed successfully.\")\n",
    "\n",
    "        # Report gradients\n",
    "        print(\"\\n🔍 Parameter gradient check:\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if param.grad is None:\n",
    "                    print(f\"⚠️  Parameter '{name}' has no gradient!\")\n",
    "                else:\n",
    "                    print(f\"✔️  '{name}': grad norm = {param.grad.norm().item():.4f}\")\n",
    "            else:\n",
    "                print(f\"ℹ️  '{name}' does not require grad.\")\n",
    "\n",
    "        # Report unused modules\n",
    "        print(\"\\n🧩 Inactive modules (not used in forward pass):\")\n",
    "        for module in model.modules():\n",
    "            # Ignore root model and container modules (Sequential, ModuleList)\n",
    "            if module not in visited_modules and module != model and \\\n",
    "            not isinstance(module, (nn.Sequential, nn.ModuleList, nn.ModuleDict)):\n",
    "                print(f\"⚠️  {module.__class__.__name__} at {module}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during verification: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "\n",
    "NAFNet3D = NAFNet3D_modulated(width=16,enc_blk_nums=[2,2,2,2],middle_blk_num=2,dec_blk_nums=[2,2,2,2],block_type = BaselineBlock_SCA,style_dim=5, modulate_outer_convs=False)\n",
    "input_shape = (2, 3, 64, 64, 64)  \n",
    "output_shape = (2, 3, 64, 64, 64) \n",
    "style_shape = (2, 5) \n",
    "verify_model(NAFNet3D, input_shape, output_shape, style_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass completed successfully.\n",
      "Output shape: torch.Size([1, 3, 32, 32, 32])\n",
      "Backward pass completed successfully.\n",
      "Parameter model.intro.weight gradient norm: 0.6609\n",
      "Parameter model.intro.bias gradient norm: 0.0307\n",
      "Parameter model.ending.weight gradient norm: 3.0512\n",
      "Parameter model.ending.bias gradient norm: 0.0508\n",
      "Parameter model.encoders.0.0.beta gradient norm: 0.0022\n",
      "Parameter model.encoders.0.0.gamma gradient norm: 0.0039\n",
      "Parameter model.encoders.0.0.conv1.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.conv1.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.conv2.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.conv2.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.conv3.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.conv3.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.sca.1.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.sca.1.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.conv4.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.conv4.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.conv5.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.conv5.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.norm1.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.norm1.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.norm2.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.0.0.norm2.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.beta gradient norm: 0.0004\n",
      "Parameter model.encoders.1.0.gamma gradient norm: 0.0009\n",
      "Parameter model.encoders.1.0.conv1.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.conv1.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.conv2.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.conv2.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.conv3.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.conv3.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.sca.1.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.sca.1.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.conv4.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.conv4.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.conv5.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.conv5.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.norm1.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.norm1.bias gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.norm2.weight gradient norm: 0.0000\n",
      "Parameter model.encoders.1.0.norm2.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.beta gradient norm: 0.0003\n",
      "Parameter model.decoders.0.0.gamma gradient norm: 0.0007\n",
      "Parameter model.decoders.0.0.conv1.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.conv1.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.conv2.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.conv2.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.conv3.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.conv3.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.sca.1.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.sca.1.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.conv4.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.conv4.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.conv5.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.conv5.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.norm1.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.norm1.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.norm2.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.0.0.norm2.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.beta gradient norm: 0.0022\n",
      "Parameter model.decoders.1.0.gamma gradient norm: 0.0038\n",
      "Parameter model.decoders.1.0.conv1.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.conv1.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.conv2.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.conv2.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.conv3.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.conv3.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.sca.1.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.sca.1.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.conv4.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.conv4.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.conv5.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.conv5.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.norm1.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.norm1.bias gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.norm2.weight gradient norm: 0.0000\n",
      "Parameter model.decoders.1.0.norm2.bias gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.beta gradient norm: 0.0001\n",
      "Parameter model.middle_blks.0.gamma gradient norm: 0.0003\n",
      "Parameter model.middle_blks.0.conv1.weight gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.conv1.bias gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.conv2.weight gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.conv2.bias gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.conv3.weight gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.conv3.bias gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.sca.1.weight gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.sca.1.bias gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.conv4.weight gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.conv4.bias gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.conv5.weight gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.conv5.bias gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.norm1.weight gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.norm1.bias gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.norm2.weight gradient norm: 0.0000\n",
      "Parameter model.middle_blks.0.norm2.bias gradient norm: 0.0000\n",
      "Parameter model.ups.0.0.weight gradient norm: 0.0119\n",
      "Parameter model.ups.1.0.weight gradient norm: 0.0787\n",
      "Parameter model.downs.0.weight gradient norm: 0.1598\n",
      "Parameter model.downs.0.bias gradient norm: 0.0074\n",
      "Parameter model.downs.1.weight gradient norm: 0.0237\n",
      "Parameter model.downs.1.bias gradient norm: 0.0020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"/home/user/ckwan1/ml/configs/new_config/naf_denoise_coslr.yaml\"\n",
    "config = load_config(path)\n",
    "config['model']['batch_size'] = config['data']['batch_size']\n",
    "config['model']['max_epochs'] = config['trainer']['max_epochs']\n",
    "config['model']['naf_middle_blk_num'] = 1\n",
    "config['model']['naf_enc_blk_nums']  = [1,1]\n",
    "config['model']['naf_dec_blk_nums']  = [1,1]\n",
    "model = Lpt2NbodyNetLightning(**config['model'])\n",
    "input_shape = (1, 3, 32, 32, 32)  \n",
    "output_shape = (1, 3, 32, 32, 32)  \n",
    "verify_model(model, input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/ckwan1/.conda/envs/d3m/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datapile import HuggingfaceLoader\n",
    "data = HuggingfaceLoader(\n",
    "        dataset_path = '/home/user/ckwan1/ml_project/sobol_hfdataset',\n",
    "        shuffle = False,\n",
    "        batch_size = 1,\n",
    "        num_workers = 1,\n",
    "        augment = False,\n",
    "        velocity = False,\n",
    "        density = False,\n",
    "        init_density= False,\n",
    "        style=['Om','h','ns','s8'],\n",
    "        redshift=0.0\n",
    "    )\n",
    "data.setup(\"validation\")\n",
    "val_iter = iter(data.val_dataloader())\n",
    "batch = next(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "batch[2].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "datasets.load_from_disk(self.hparams.dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32, 32])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "hdf5_path = '/home/user/ckwan1/ml_project/sobol_32_hdf5/25/Cosmo4_Om0p120469_h0p656280_ns0p808474_s80p787739_z0/data.h5'\n",
    "with h5py.File(hdf5_path, 'r') as f:\n",
    "    displacement = torch.from_numpy(np.einsum('ijkc->cijk', f['displacement'][()])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 32, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displacement.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LPT = displacement[6:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LPT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "step must be greater than zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m LPT \u001b[38;5;241m=\u001b[39m LPT[:, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: step must be greater than zero"
     ]
    }
   ],
   "source": [
    "LPT = LPT[:, ::-1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(hdf5_path, 'r') as f:\n",
    "    d=f['displacement'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7ff025afe720>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(batch[0][0,0,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7ff026f2c3b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(batch[1][0,0,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/ckwan1/.conda/envs/d3m/lib/python3.12/site-packages/lightning/pytorch/core/module.py:445: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from model import Lpt2NbodyNetLightning\n",
    "import yaml\n",
    "file_path = '/home/user/ckwan1/ml/configs/new_config/score_model_adam_gc_reverse_init_density_individual_std1and2.yaml'\n",
    "with open(file_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "config['model']['batch_size'] = config['data']['batch_size']\n",
    "config['model']['max_epochs'] = config['trainer']['max_epochs']\n",
    "config['model']['used_density'] = config['data']['density']\n",
    "config['model']['ch_mult'] = [1]\n",
    "model = Lpt2NbodyNetLightning(**config['model'])\n",
    "\n",
    "optimizer = model.configure_optimizers()\n",
    "x = torch.randn(1, 1, 32, 32, 32)\n",
    "y = torch.randn(1, 1, 32, 32, 32)\n",
    "# Forward pass\n",
    "loss = model.training_step((x,y),batch_idx=0)\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters in LightningModule BEFORE Trainer.fit():\n",
      "  model.encoders.0.0.conv.style_weight - requires_grad: True\n",
      "  model.encoders.0.0.conv.style_bias - requires_grad: True\n",
      "  model.encoders.0.0.conv.weight - requires_grad: True\n",
      "  model.encoders.0.0.conv.bias - requires_grad: True\n",
      "  model.encoders.0.0.bn.weight - requires_grad: True\n",
      "  model.encoders.0.0.bn.bias - requires_grad: True\n",
      "  model.encoders.1.0.conv.style_weight - requires_grad: True\n",
      "  model.encoders.1.0.conv.style_bias - requires_grad: True\n",
      "  model.encoders.1.0.conv.weight - requires_grad: True\n",
      "  model.encoders.1.0.conv.bias - requires_grad: True\n",
      "  model.encoders.1.0.bn.weight - requires_grad: True\n",
      "  model.encoders.1.0.bn.bias - requires_grad: True\n",
      "  model.encoders.2.0.conv.style_weight - requires_grad: True\n",
      "  model.encoders.2.0.conv.style_bias - requires_grad: True\n",
      "  model.encoders.2.0.conv.weight - requires_grad: True\n",
      "  model.encoders.2.0.conv.bias - requires_grad: True\n",
      "  model.encoders.2.0.bn.weight - requires_grad: True\n",
      "  model.encoders.2.0.bn.bias - requires_grad: True\n",
      "  model.encoders.3.0.conv.style_weight - requires_grad: True\n",
      "  model.encoders.3.0.conv.style_bias - requires_grad: True\n",
      "  model.encoders.3.0.conv.weight - requires_grad: True\n",
      "  model.encoders.3.0.conv.bias - requires_grad: True\n",
      "  model.encoders.3.0.bn.weight - requires_grad: True\n",
      "  model.encoders.3.0.bn.bias - requires_grad: True\n",
      "  model.decoders.0.style_weight - requires_grad: True\n",
      "  model.decoders.0.style_bias - requires_grad: True\n",
      "  model.decoders.0.weight - requires_grad: True\n",
      "  model.decoders.0.bias - requires_grad: True\n",
      "  model.decoders.1.0.conv.style_weight - requires_grad: True\n",
      "  model.decoders.1.0.conv.style_bias - requires_grad: True\n",
      "  model.decoders.1.0.conv.weight - requires_grad: True\n",
      "  model.decoders.1.0.conv.bias - requires_grad: True\n",
      "  model.decoders.1.0.bn.weight - requires_grad: True\n",
      "  model.decoders.1.0.bn.bias - requires_grad: True\n",
      "  model.decoders.2.style_weight - requires_grad: True\n",
      "  model.decoders.2.style_bias - requires_grad: True\n",
      "  model.decoders.2.weight - requires_grad: True\n",
      "  model.decoders.2.bias - requires_grad: True\n",
      "  model.decoders.3.0.conv.style_weight - requires_grad: True\n",
      "  model.decoders.3.0.conv.style_bias - requires_grad: True\n",
      "  model.decoders.3.0.conv.weight - requires_grad: True\n",
      "  model.decoders.3.0.conv.bias - requires_grad: True\n",
      "  model.decoders.3.0.bn.weight - requires_grad: True\n",
      "  model.decoders.3.0.bn.bias - requires_grad: True\n",
      "  model.init_conv.0.conv.style_weight - requires_grad: True\n",
      "  model.init_conv.0.conv.style_bias - requires_grad: True\n",
      "  model.init_conv.0.conv.weight - requires_grad: True\n",
      "  model.init_conv.0.conv.bias - requires_grad: True\n",
      "  model.init_conv.0.bn.weight - requires_grad: True\n",
      "  model.init_conv.0.bn.bias - requires_grad: True\n",
      "  model.final_conv.style_weight - requires_grad: True\n",
      "  model.final_conv.style_bias - requires_grad: True\n",
      "  model.final_conv.weight - requires_grad: True\n",
      "  model.final_conv.bias - requires_grad: True\n",
      "  OK: Trainable parameters found in LightningModule instance before fit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "W0525 18:34:40.228000 1200725 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 1203027 via signal SIGTERM\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 1 terminated with signal SIGSEGV",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 100\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Configure Trainer for DDP (adjust accelerator and devices as needed)\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Make sure you have at least 2 GPUs available or use 'ddp_spawn' for CPU testing\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# For CPU testing of DDP logic (slower):\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# trainer = pl.Trainer(max_epochs=1, strategy='ddp_spawn', accelerator='cpu', devices=2)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# For GPU:\u001b[39;00m\n\u001b[1;32m     93\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     94\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     95\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# strategy='ddp' # Simpler DDP\u001b[39;00m\n\u001b[1;32m     99\u001b[0m )\n\u001b[0;32m--> 100\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(lit_model, datamodule\u001b[38;5;241m=\u001b[39mdata_module)\n",
      "File \u001b[0;32m~/.conda/envs/d3m/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    540\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/d3m/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:46\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/.conda/envs/d3m/lib/python3.12/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py:144\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m process_context \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mstart_processes(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapping_function,\n\u001b[1;32m    138\u001b[0m     args\u001b[38;5;241m=\u001b[39mprocess_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# we will join ourselves to get the process references\u001b[39;00m\n\u001b[1;32m    142\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocs \u001b[38;5;241m=\u001b[39m process_context\u001b[38;5;241m.\u001b[39mprocesses\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m process_context\u001b[38;5;241m.\u001b[39mjoin():\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    147\u001b[0m worker_output \u001b[38;5;241m=\u001b[39m return_queue\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m~/.conda/envs/d3m/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:184\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m         name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Unknown signal \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m-\u001b[39mexitcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, name),\n\u001b[1;32m    186\u001b[0m         error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    187\u001b[0m         error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    188\u001b[0m         exit_code\u001b[38;5;241m=\u001b[39mexitcode,\n\u001b[1;32m    189\u001b[0m         signal_name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, exitcode),\n\u001b[1;32m    194\u001b[0m         error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    195\u001b[0m         error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    196\u001b[0m         exit_code\u001b[38;5;241m=\u001b[39mexitcode,\n\u001b[1;32m    197\u001b[0m     )\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 1 terminated with signal SIGSEGV"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "# from your_unet_file import StyledUNet3D # Make sure this import works\n",
    "from unet import StyledUNet3D # Assuming unet.py is in the same directory or accessible\n",
    "\n",
    "class MinimalLitModel(pl.LightningModule):\n",
    "    def __init__(self, style_size, num_layers, base_filters, blocks_per_layer, init_dim, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters() # Saves init args to hparams\n",
    "\n",
    "        self.model = StyledUNet3D(\n",
    "            style_size=style_size,\n",
    "            num_layers=num_layers,\n",
    "            base_filters=base_filters,\n",
    "            blocks_per_layer=blocks_per_layer,\n",
    "            init_dim=init_dim\n",
    "        )\n",
    "        self.criterion = nn.MSELoss() # Example loss\n",
    "\n",
    "    def forward(self, x, s):\n",
    "        return self.model(x, s)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, s, y_true = batch # Assuming batch is (input_image, style_vector, target_image)\n",
    "        y_pred = self(x, s)\n",
    "        loss = self.criterion(y_pred, y_true)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "# Dummy DataModule (replace with your actual data)\n",
    "class DummyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=2, style_size=5, dim=32, init_dim=3):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.style_size = style_size\n",
    "        self.dim = dim\n",
    "        self.init_dim = init_dim\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Create dummy data that matches your model's expected input\n",
    "        # (batch, channels, D, H, W) for x and y_true\n",
    "        # (batch, style_size) for s\n",
    "        x = torch.randn(self.batch_size, self.init_dim, self.dim, self.dim, self.dim)\n",
    "        s = torch.randn(self.batch_size, self.style_size)\n",
    "        y_true = torch.randn(self.batch_size, self.init_dim, self.dim, self.dim, self.dim) # Assuming output has same channels as input\n",
    "        dataset = torch.utils.data.TensorDataset(x, s, y_true)\n",
    "        return torch.utils.data.DataLoader(dataset, batch_size=self.batch_size)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Model Hyperparameters (match what you used in the standalone test)\n",
    "    style_size = 5\n",
    "    num_layers = 2\n",
    "    base_filters = 16\n",
    "    blocks_per_layer = 1\n",
    "    init_dim = 3\n",
    "\n",
    "    lit_model = MinimalLitModel(\n",
    "        style_size=style_size,\n",
    "        num_layers=num_layers,\n",
    "        base_filters=base_filters,\n",
    "        blocks_per_layer=blocks_per_layer,\n",
    "        init_dim=init_dim\n",
    "    )\n",
    "\n",
    "    # --- Check parameters within LightningModule context BEFORE training ---\n",
    "    print(\"Parameters in LightningModule BEFORE Trainer.fit():\")\n",
    "    found_trainable_in_lit = False\n",
    "    for name, param in lit_model.named_parameters(): # This will include model params\n",
    "        if param.requires_grad:\n",
    "            print(f\"  {name} - requires_grad: {param.requires_grad}\")\n",
    "            found_trainable_in_lit = True\n",
    "    if not found_trainable_in_lit:\n",
    "        print(\"  ERROR: No trainable parameters found in LightningModule instance before fit!\")\n",
    "    else:\n",
    "        print(\"  OK: Trainable parameters found in LightningModule instance before fit.\")\n",
    "    # --- End Check ---\n",
    "\n",
    "\n",
    "    data_module = DummyDataModule(batch_size=2, style_size=style_size, init_dim=init_dim)\n",
    "\n",
    "    # Configure Trainer for DDP (adjust accelerator and devices as needed)\n",
    "    # Make sure you have at least 2 GPUs available or use 'ddp_spawn' for CPU testing\n",
    "    # For CPU testing of DDP logic (slower):\n",
    "    # trainer = pl.Trainer(max_epochs=1, strategy='ddp_spawn', accelerator='cpu', devices=2)\n",
    "\n",
    "    # For GPU:\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=1,\n",
    "        accelerator='cpu',\n",
    "        devices=2, # Use 1 for initial testing, then try 2 if you have them\n",
    "        strategy='ddp_notebook'\n",
    "        # strategy='ddp' # Simpler DDP\n",
    "    )\n",
    "    trainer.fit(lit_model, datamodule=data_module)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
